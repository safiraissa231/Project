{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Package dan Importing Module"
      ],
      "metadata": {
        "id": "v4ISDkBwG4q1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpSx5RQaoiK0",
        "outputId": "de82fd0d-4159-4008-b002-6063df5a8209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-8.0.33-cp310-cp310-manylinux1_x86_64.whl (27.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.3,>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from mysql-connector-python) (3.20.3)\n",
            "Installing collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-8.0.33\n"
          ]
        }
      ],
      "source": [
        "# Installing this package to connected our python file with our dataset that we already have in mysql\n",
        "!pip install mysql-connector-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing mysql.connector module that's been installed\n",
        "import mysql.connector"
      ],
      "metadata": {
        "id": "8XrhhSBxLP9F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing pandas module that used for processing dataframe (in here is our dataset which is in csv format)\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-NcSRKpvLT3g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing keras-tuner package\n",
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h37opzUDLdhZ",
        "outputId": "f3c13f42-ac4a-425d-9818-8f757116a4fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing tensorflow\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "OQ8u_wyBLnqu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modul from tensorflow.keras to pre-processing text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "oDCDZCpQM5-A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modul from tensorflow.keras to make model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "n9vPZjPTNLwY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing regex module that used for pre-processing (cleaning text data)\n",
        "import re"
      ],
      "metadata": {
        "id": "O_JGRUucLo2N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing pandas module that used for processing dataframe (in here is our dataset which is in csv format)\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hKmXyz2QNjuu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing numpy module to provide mathematical operations in arrays\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ccDCFkYXLqC3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing nltk module that used for pre-processing (cleaning text data)\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufb77oF4LvfA",
        "outputId": "6ae22297-b06d-41ea-c3dd-d172259159f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "e_MqnJL6LuFV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oMcASR-0oiEV"
      },
      "outputs": [],
      "source": [
        "# Replace the placeholders with your own values\n",
        "connection_name = 'c23df02-diskusai:asia-southeast2:diskusaidataset'\n",
        "ip_address = '34.101.70.233'\n",
        "db_name = 'diskusaidataset'\n",
        "user = 'root'\n",
        "password = 'df02'\n",
        "\n",
        "# Create the connection string\n",
        "connection_string = f\"mysql+mysqlconnector://{user}:{password}@{ip_address}/{db_name}?unix_socket=/cloudsql/{connection_name}\"\n",
        "\n",
        "# Establish the connection\n",
        "cnx = mysql.connector.connect(user=user, password=password, host=ip_address, database=db_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h5UDEeSWoiAk"
      },
      "outputs": [],
      "source": [
        "# Replace 'your_table_name' with the actual name of your table\n",
        "query = \"SELECT * FROM diskusaidataset\"\n",
        "\n",
        "# Execute the query\n",
        "cursor = cnx.cursor()\n",
        "cursor.execute(query)\n",
        "\n",
        "# Fetch all the results\n",
        "data = cursor.fetchall()\n",
        "\n",
        "# Convert the data into a Pandas DataFrame\n",
        "dataset = pd.DataFrame(data, columns=cursor.column_names)\n",
        "\n",
        "# Close the cursor and connection\n",
        "cursor.close()\n",
        "cnx.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YvrJlFpXn9ff"
      },
      "outputs": [],
      "source": [
        "# Cleaning question column from special characters that don't exist in regex module\n",
        "dataset['question'] = dataset['question'].str.replace('<p>', '')\n",
        "dataset['question'] = dataset['question'].str.replace('<h2>', '')\n",
        "dataset['question'] = dataset['question'].str.replace('</h2>', '')\n",
        "dataset['question'] = dataset['question'].str.replace('<h3>', '')\n",
        "dataset['question'] = dataset['question'].str.replace('</h3>', '')\n",
        "dataset['question'] = dataset['question'].str.replace('</p>', '')\n",
        "dataset['question'] = dataset['question'].str.replace('<strong>', '')\n",
        "dataset['question'] = dataset['question'].str.replace('</strong>', '')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new dataset that contained only 1 column called 'sentence' consisted from \"module_name\", \"discussion_title\", \"question\" columns\n",
        "data1=((dataset[\"module_name\"]).values).tolist()\n",
        "data2=((dataset[\"discussion_title\"]).values).tolist()\n",
        "data3=((dataset[\"question\"]).values).tolist()\n",
        "data=data1+data2+data3\n",
        "df = pd.DataFrame(data, columns=['sentence'])"
      ],
      "metadata": {
        "id": "fKz76pffs8tM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpj9B-SVDJCP",
        "outputId": "cecb639f-7431-4b38-d133-9899636d1d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning sentences...\n"
          ]
        }
      ],
      "source": [
        "# Cleaning Data Text\n",
        "\n",
        "STOPWORDS1 = set(stopwords.words('indonesian'))\n",
        "STOPWORDS2 = set(stopwords.words('english'))\n",
        "MIN_WORDS = 4\n",
        "MAX_WORDS = 200\n",
        "\n",
        "PATTERN_S = re.compile(\"\\'s\")  # matches `'s` from text  \n",
        "PATTERN_RN = re.compile(\"\\\\r\\\\n\") #matches `\\r` and `\\n`\n",
        "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\") # matches all non 0-9 A-z whitespace \n",
        "\n",
        "# Defining function to clean data text using regex module\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Series of cleaning. String to lower case, remove non words characters and numbers.\n",
        "        text (str): input text\n",
        "    return (str): modified initial text\n",
        "    \"\"\"\n",
        "    text = text.lower()  # lowercase text\n",
        "    text = re.sub(PATTERN_S, ' ', text)\n",
        "    text = re.sub(PATTERN_RN, ' ', text)\n",
        "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
        "    return text\n",
        "\n",
        "# Defining tokenizer1 to clean data text using indonesian stopwords\n",
        "def tokenizer1(sentence, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS1, lemmatize=True):\n",
        "    \"\"\"\n",
        "    Lemmatize, tokenize, crop and remove stop words.\n",
        "    \"\"\"\n",
        "    stemmer = WordNetLemmatizer()\n",
        "    tokens1 = [stemmer.lemmatize(w) for w in word_tokenize(sentence)]\n",
        "    tokens1 = ' '.join(tokens1)\n",
        "    return tokens1    \n",
        "\n",
        "# Defining tokenizer2 to clean data text using english stopwords\n",
        "def tokenizer2(sentence, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS2, lemmatize=True):\n",
        "    \"\"\"\n",
        "    Lemmatize, tokenize, crop and remove stop words.\n",
        "    \"\"\"\n",
        "    stemmer = WordNetLemmatizer()\n",
        "    tokens2 = [stemmer.lemmatize(w) for w in word_tokenize(sentence)]\n",
        "    tokens2 = ' '.join(tokens2)\n",
        "    return tokens2    \n",
        "\n",
        "# Defining clean_sentences to apply all cleaning data text process to our dataset\n",
        "def clean_sentences(df):\n",
        "    \"\"\"\n",
        "    Remove irrelavant characters (in new column clean_sentence).\n",
        "    Lemmatize, tokenize words into list of words (in new column tok_lem_sentence).\n",
        "    \"\"\"\n",
        "    print('Cleaning sentences...')\n",
        "    df['sentence'] = df['sentence'].apply(clean_text)\n",
        "    df['sentence'] = df['sentence'].apply(\n",
        "        lambda x: tokenizer1(x, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS1, lemmatize=True))\n",
        "    df['sentence'] = df['sentence'].apply(\n",
        "        lambda x: tokenizer2(x, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS2, lemmatize=True))\n",
        "    return df\n",
        "\n",
        "# Applying all cleaning data text process to our dataset \n",
        "df = clean_sentences(df)\n",
        "\n",
        "# Creating tokes from our cleaned dataset\n",
        "tokens = df['sentence'].str.split()\n",
        "tokens = [word for sublist in tokens for word in sublist]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing and Padding"
      ],
      "metadata": {
        "id": "gj_Y22lCPsWc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hpgYAKdBzm26"
      },
      "outputs": [],
      "source": [
        "# Tokenizing our text data\n",
        "tokenizer = Tokenizer(oov_token='<oov>') \n",
        "tokenizer.fit_on_texts(tokens)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbK7rGJYn9fx",
        "outputId": "63ef2f27-52e5-4337-8965-d4ecacbaeffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total input sequences:  5277\n"
          ]
        }
      ],
      "source": [
        "# Creating input sequences\n",
        "input_sequences = []\n",
        "for line in tokens:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    #print(token_list)\n",
        "    \n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "print(\"Total input sequences: \", len(input_sequences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EC_Oajm_N7d_"
      },
      "outputs": [],
      "source": [
        "# Setting max sequence len for each input sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding input sequences\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ],
      "metadata": {
        "id": "jPbbOp1vPxiz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Feature and Label"
      ],
      "metadata": {
        "id": "mvAP90MgQhb4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dPhKOzb4N_6d"
      },
      "outputs": [],
      "source": [
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Model"
      ],
      "metadata": {
        "id": "3bbKDUthQsBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FussNXDjOIYH"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 32, input_length=max_sequence_len-1))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(128,kernel_regularizer=tf.keras.regularizers.l2(0.001),recurrent_regularizer=tf.keras.regularizers.l2(0.001))))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(total_words, activation='softmax',kernel_regularizer=tf.keras.regularizers.l2(0.001)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Costumized Adam Optimizers"
      ],
      "metadata": {
        "id": "iMhZqHFSQ89_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.95)\n",
        "optimizers = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "metadata": {
        "id": "lGyXi7d-MIq4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling Model"
      ],
      "metadata": {
        "id": "ifJeJcv3RF7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2oKYw14kMLrK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "-UnfwiHCRLTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(xs, ys, epochs=1000, validation_split=0.1, verbose=1)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKEP-QpPMOAO",
        "outputId": "ecd6e480-107c-4fd9-cc77-4a056b890ba7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.3243 - accuracy: 0.6555 - val_loss: 2.4780 - val_accuracy: 0.7670\n",
            "Epoch 2/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.2716 - accuracy: 0.6679 - val_loss: 2.3639 - val_accuracy: 0.7569\n",
            "Epoch 3/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.2624 - accuracy: 0.6572 - val_loss: 2.3975 - val_accuracy: 0.7557\n",
            "Epoch 4/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.2758 - accuracy: 0.6677 - val_loss: 2.3666 - val_accuracy: 0.7595\n",
            "Epoch 5/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.2347 - accuracy: 0.6702 - val_loss: 2.3790 - val_accuracy: 0.7342\n",
            "Epoch 6/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.2513 - accuracy: 0.6633 - val_loss: 2.2813 - val_accuracy: 0.7872\n",
            "Epoch 7/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.2259 - accuracy: 0.6679 - val_loss: 2.2626 - val_accuracy: 0.7645\n",
            "Epoch 8/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.1954 - accuracy: 0.6688 - val_loss: 2.2906 - val_accuracy: 0.7620\n",
            "Epoch 9/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.1860 - accuracy: 0.6681 - val_loss: 2.2417 - val_accuracy: 0.7683\n",
            "Epoch 10/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.1967 - accuracy: 0.6700 - val_loss: 2.2250 - val_accuracy: 0.7683\n",
            "Epoch 11/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.1757 - accuracy: 0.6673 - val_loss: 2.2249 - val_accuracy: 0.7633\n",
            "Epoch 12/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.1575 - accuracy: 0.6719 - val_loss: 2.2496 - val_accuracy: 0.7159\n",
            "Epoch 13/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.1471 - accuracy: 0.6660 - val_loss: 2.2095 - val_accuracy: 0.7784\n",
            "Epoch 14/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.1320 - accuracy: 0.6728 - val_loss: 2.1782 - val_accuracy: 0.7784\n",
            "Epoch 15/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.1579 - accuracy: 0.6654 - val_loss: 2.1702 - val_accuracy: 0.7822\n",
            "Epoch 16/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.1457 - accuracy: 0.6730 - val_loss: 2.1947 - val_accuracy: 0.7822\n",
            "Epoch 17/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.1373 - accuracy: 0.6681 - val_loss: 2.1418 - val_accuracy: 0.7973\n",
            "Epoch 18/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 2.1292 - accuracy: 0.6749 - val_loss: 2.0882 - val_accuracy: 0.7967\n",
            "Epoch 19/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.1100 - accuracy: 0.6734 - val_loss: 2.1462 - val_accuracy: 0.7702\n",
            "Epoch 20/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0868 - accuracy: 0.6785 - val_loss: 2.1306 - val_accuracy: 0.7753\n",
            "Epoch 21/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.1587 - accuracy: 0.6665 - val_loss: 2.1961 - val_accuracy: 0.7702\n",
            "Epoch 22/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.1342 - accuracy: 0.6713 - val_loss: 2.1501 - val_accuracy: 0.7753\n",
            "Epoch 23/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.1389 - accuracy: 0.6654 - val_loss: 2.1289 - val_accuracy: 0.7740\n",
            "Epoch 24/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.1388 - accuracy: 0.6721 - val_loss: 2.1243 - val_accuracy: 0.7854\n",
            "Epoch 25/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.1433 - accuracy: 0.6726 - val_loss: 2.0967 - val_accuracy: 0.7879\n",
            "Epoch 26/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 2.1147 - accuracy: 0.6745 - val_loss: 2.1254 - val_accuracy: 0.7670\n",
            "Epoch 27/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.1563 - accuracy: 0.6700 - val_loss: 2.1425 - val_accuracy: 0.7790\n",
            "Epoch 28/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.1173 - accuracy: 0.6745 - val_loss: 2.1229 - val_accuracy: 0.7879\n",
            "Epoch 29/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0985 - accuracy: 0.6728 - val_loss: 2.0932 - val_accuracy: 0.7841\n",
            "Epoch 30/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0953 - accuracy: 0.6650 - val_loss: 2.0974 - val_accuracy: 0.7822\n",
            "Epoch 31/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.1465 - accuracy: 0.6679 - val_loss: 2.1334 - val_accuracy: 0.7771\n",
            "Epoch 32/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0933 - accuracy: 0.6816 - val_loss: 2.1076 - val_accuracy: 0.7689\n",
            "Epoch 33/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.1197 - accuracy: 0.6702 - val_loss: 2.0952 - val_accuracy: 0.7784\n",
            "Epoch 34/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.1032 - accuracy: 0.6768 - val_loss: 2.1243 - val_accuracy: 0.7797\n",
            "Epoch 35/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0935 - accuracy: 0.6749 - val_loss: 2.1547 - val_accuracy: 0.7759\n",
            "Epoch 36/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.1093 - accuracy: 0.6702 - val_loss: 2.1376 - val_accuracy: 0.7923\n",
            "Epoch 37/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 2.0900 - accuracy: 0.6690 - val_loss: 2.0691 - val_accuracy: 0.7822\n",
            "Epoch 38/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.0780 - accuracy: 0.6797 - val_loss: 2.0753 - val_accuracy: 0.7835\n",
            "Epoch 39/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.1402 - accuracy: 0.6694 - val_loss: 2.0642 - val_accuracy: 0.7948\n",
            "Epoch 40/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0827 - accuracy: 0.6696 - val_loss: 2.1162 - val_accuracy: 0.7816\n",
            "Epoch 41/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0656 - accuracy: 0.6747 - val_loss: 2.0858 - val_accuracy: 0.7967\n",
            "Epoch 42/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0740 - accuracy: 0.6772 - val_loss: 2.0685 - val_accuracy: 0.7797\n",
            "Epoch 43/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0845 - accuracy: 0.6749 - val_loss: 2.0648 - val_accuracy: 0.7778\n",
            "Epoch 44/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0816 - accuracy: 0.6749 - val_loss: 2.1149 - val_accuracy: 0.7835\n",
            "Epoch 45/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0885 - accuracy: 0.6702 - val_loss: 2.0243 - val_accuracy: 0.7841\n",
            "Epoch 46/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0632 - accuracy: 0.6696 - val_loss: 2.0789 - val_accuracy: 0.7753\n",
            "Epoch 47/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0996 - accuracy: 0.6677 - val_loss: 2.0603 - val_accuracy: 0.7854\n",
            "Epoch 48/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 2.0503 - accuracy: 0.6793 - val_loss: 2.0819 - val_accuracy: 0.7658\n",
            "Epoch 49/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0565 - accuracy: 0.6795 - val_loss: 2.0811 - val_accuracy: 0.7847\n",
            "Epoch 50/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0484 - accuracy: 0.6799 - val_loss: 2.0235 - val_accuracy: 0.7670\n",
            "Epoch 51/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0498 - accuracy: 0.6736 - val_loss: 2.0165 - val_accuracy: 0.7778\n",
            "Epoch 52/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0469 - accuracy: 0.6742 - val_loss: 2.0595 - val_accuracy: 0.7797\n",
            "Epoch 53/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.0800 - accuracy: 0.6684 - val_loss: 2.0700 - val_accuracy: 0.7696\n",
            "Epoch 54/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0725 - accuracy: 0.6711 - val_loss: 2.0511 - val_accuracy: 0.7999\n",
            "Epoch 55/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0310 - accuracy: 0.6764 - val_loss: 2.0297 - val_accuracy: 0.7872\n",
            "Epoch 56/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 2.0344 - accuracy: 0.6837 - val_loss: 1.9932 - val_accuracy: 0.7727\n",
            "Epoch 57/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0588 - accuracy: 0.6755 - val_loss: 2.0196 - val_accuracy: 0.7790\n",
            "Epoch 58/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0454 - accuracy: 0.6833 - val_loss: 2.0199 - val_accuracy: 0.7917\n",
            "Epoch 59/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0907 - accuracy: 0.6692 - val_loss: 2.0756 - val_accuracy: 0.7790\n",
            "Epoch 60/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.0678 - accuracy: 0.6761 - val_loss: 2.0178 - val_accuracy: 0.7759\n",
            "Epoch 61/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0570 - accuracy: 0.6789 - val_loss: 2.0553 - val_accuracy: 0.7816\n",
            "Epoch 62/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 2.0545 - accuracy: 0.6694 - val_loss: 1.9691 - val_accuracy: 0.7910\n",
            "Epoch 63/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0405 - accuracy: 0.6766 - val_loss: 2.0119 - val_accuracy: 0.7835\n",
            "Epoch 64/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.0685 - accuracy: 0.6764 - val_loss: 2.0093 - val_accuracy: 0.7866\n",
            "Epoch 65/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0523 - accuracy: 0.6740 - val_loss: 2.0074 - val_accuracy: 0.7854\n",
            "Epoch 66/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0820 - accuracy: 0.6700 - val_loss: 2.0018 - val_accuracy: 0.7917\n",
            "Epoch 67/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0565 - accuracy: 0.6713 - val_loss: 2.0316 - val_accuracy: 0.7803\n",
            "Epoch 68/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0415 - accuracy: 0.6820 - val_loss: 2.0225 - val_accuracy: 0.7910\n",
            "Epoch 69/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0071 - accuracy: 0.6814 - val_loss: 1.9969 - val_accuracy: 0.7778\n",
            "Epoch 70/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0398 - accuracy: 0.6757 - val_loss: 1.9879 - val_accuracy: 0.7961\n",
            "Epoch 71/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0164 - accuracy: 0.6787 - val_loss: 1.9740 - val_accuracy: 0.7854\n",
            "Epoch 72/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9950 - accuracy: 0.6776 - val_loss: 1.9689 - val_accuracy: 0.7715\n",
            "Epoch 73/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 2.0072 - accuracy: 0.6757 - val_loss: 1.9787 - val_accuracy: 0.7891\n",
            "Epoch 74/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0032 - accuracy: 0.6797 - val_loss: 1.9926 - val_accuracy: 0.7797\n",
            "Epoch 75/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0184 - accuracy: 0.6829 - val_loss: 1.9792 - val_accuracy: 0.7980\n",
            "Epoch 76/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0389 - accuracy: 0.6732 - val_loss: 1.9776 - val_accuracy: 0.7885\n",
            "Epoch 77/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0158 - accuracy: 0.6804 - val_loss: 1.9860 - val_accuracy: 0.7822\n",
            "Epoch 78/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0343 - accuracy: 0.6753 - val_loss: 2.0086 - val_accuracy: 0.7835\n",
            "Epoch 79/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0623 - accuracy: 0.6726 - val_loss: 2.0217 - val_accuracy: 0.7929\n",
            "Epoch 80/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0528 - accuracy: 0.6761 - val_loss: 2.1820 - val_accuracy: 0.5556\n",
            "Epoch 81/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0459 - accuracy: 0.6850 - val_loss: 2.0305 - val_accuracy: 0.7910\n",
            "Epoch 82/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0317 - accuracy: 0.6774 - val_loss: 2.0138 - val_accuracy: 0.7860\n",
            "Epoch 83/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0360 - accuracy: 0.6827 - val_loss: 2.0017 - val_accuracy: 0.7917\n",
            "Epoch 84/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.0372 - accuracy: 0.6761 - val_loss: 2.0834 - val_accuracy: 0.7891\n",
            "Epoch 85/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0989 - accuracy: 0.6738 - val_loss: 2.0110 - val_accuracy: 0.7955\n",
            "Epoch 86/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.0421 - accuracy: 0.6721 - val_loss: 1.9734 - val_accuracy: 0.8030\n",
            "Epoch 87/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0517 - accuracy: 0.6825 - val_loss: 1.9827 - val_accuracy: 0.8112\n",
            "Epoch 88/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0391 - accuracy: 0.6740 - val_loss: 1.9808 - val_accuracy: 0.7860\n",
            "Epoch 89/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0323 - accuracy: 0.6785 - val_loss: 2.0261 - val_accuracy: 0.7885\n",
            "Epoch 90/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0351 - accuracy: 0.6816 - val_loss: 1.9616 - val_accuracy: 0.8049\n",
            "Epoch 91/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0001 - accuracy: 0.6848 - val_loss: 1.9891 - val_accuracy: 0.7835\n",
            "Epoch 92/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 2.0259 - accuracy: 0.6766 - val_loss: 2.0570 - val_accuracy: 0.7917\n",
            "Epoch 93/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0248 - accuracy: 0.6829 - val_loss: 1.9603 - val_accuracy: 0.8056\n",
            "Epoch 94/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0627 - accuracy: 0.6719 - val_loss: 2.0113 - val_accuracy: 0.7835\n",
            "Epoch 95/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0178 - accuracy: 0.6831 - val_loss: 1.9776 - val_accuracy: 0.7992\n",
            "Epoch 96/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0015 - accuracy: 0.6837 - val_loss: 1.9725 - val_accuracy: 0.7917\n",
            "Epoch 97/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9933 - accuracy: 0.6839 - val_loss: 2.0028 - val_accuracy: 0.7898\n",
            "Epoch 98/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0130 - accuracy: 0.6831 - val_loss: 2.0789 - val_accuracy: 0.7652\n",
            "Epoch 99/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0049 - accuracy: 0.6721 - val_loss: 1.9665 - val_accuracy: 0.7992\n",
            "Epoch 100/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0136 - accuracy: 0.6753 - val_loss: 1.9624 - val_accuracy: 0.7923\n",
            "Epoch 101/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9802 - accuracy: 0.6860 - val_loss: 1.9559 - val_accuracy: 0.8030\n",
            "Epoch 102/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9900 - accuracy: 0.6816 - val_loss: 1.9489 - val_accuracy: 0.8049\n",
            "Epoch 103/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.9864 - accuracy: 0.6833 - val_loss: 1.9582 - val_accuracy: 0.7948\n",
            "Epoch 104/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0205 - accuracy: 0.6753 - val_loss: 2.0086 - val_accuracy: 0.7967\n",
            "Epoch 105/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0374 - accuracy: 0.6846 - val_loss: 1.9940 - val_accuracy: 0.7961\n",
            "Epoch 106/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 2.0215 - accuracy: 0.6808 - val_loss: 2.0618 - val_accuracy: 0.7702\n",
            "Epoch 107/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0198 - accuracy: 0.6791 - val_loss: 1.9880 - val_accuracy: 0.7999\n",
            "Epoch 108/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0178 - accuracy: 0.6793 - val_loss: 2.0047 - val_accuracy: 0.7980\n",
            "Epoch 109/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0564 - accuracy: 0.6780 - val_loss: 1.9801 - val_accuracy: 0.7923\n",
            "Epoch 110/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0665 - accuracy: 0.6774 - val_loss: 2.0220 - val_accuracy: 0.7936\n",
            "Epoch 111/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.0616 - accuracy: 0.6764 - val_loss: 2.0168 - val_accuracy: 0.7936\n",
            "Epoch 112/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0177 - accuracy: 0.6804 - val_loss: 1.9858 - val_accuracy: 0.7885\n",
            "Epoch 113/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0105 - accuracy: 0.6854 - val_loss: 2.0025 - val_accuracy: 0.7967\n",
            "Epoch 114/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 2.0225 - accuracy: 0.6844 - val_loss: 2.0059 - val_accuracy: 0.7866\n",
            "Epoch 115/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 2.0159 - accuracy: 0.6852 - val_loss: 1.9892 - val_accuracy: 0.8043\n",
            "Epoch 116/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0616 - accuracy: 0.6774 - val_loss: 2.0625 - val_accuracy: 0.7999\n",
            "Epoch 117/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0300 - accuracy: 0.6785 - val_loss: 2.0010 - val_accuracy: 0.7759\n",
            "Epoch 118/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9920 - accuracy: 0.6831 - val_loss: 2.0271 - val_accuracy: 0.7797\n",
            "Epoch 119/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0027 - accuracy: 0.6797 - val_loss: 2.0239 - val_accuracy: 0.7822\n",
            "Epoch 120/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0037 - accuracy: 0.6810 - val_loss: 1.9971 - val_accuracy: 0.8068\n",
            "Epoch 121/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9693 - accuracy: 0.6856 - val_loss: 1.9855 - val_accuracy: 0.7929\n",
            "Epoch 122/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9708 - accuracy: 0.6900 - val_loss: 1.9445 - val_accuracy: 0.8018\n",
            "Epoch 123/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9986 - accuracy: 0.6812 - val_loss: 1.9394 - val_accuracy: 0.8074\n",
            "Epoch 124/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9663 - accuracy: 0.6865 - val_loss: 1.9420 - val_accuracy: 0.7936\n",
            "Epoch 125/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.9688 - accuracy: 0.6848 - val_loss: 1.9573 - val_accuracy: 0.8018\n",
            "Epoch 126/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9864 - accuracy: 0.6825 - val_loss: 1.9933 - val_accuracy: 0.7835\n",
            "Epoch 127/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0128 - accuracy: 0.6755 - val_loss: 1.9718 - val_accuracy: 0.7992\n",
            "Epoch 128/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0161 - accuracy: 0.6814 - val_loss: 1.9890 - val_accuracy: 0.7973\n",
            "Epoch 129/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9741 - accuracy: 0.6892 - val_loss: 1.9329 - val_accuracy: 0.7955\n",
            "Epoch 130/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9680 - accuracy: 0.6854 - val_loss: 1.9313 - val_accuracy: 0.7948\n",
            "Epoch 131/1000\n",
            "149/149 [==============================] - 4s 28ms/step - loss: 1.9624 - accuracy: 0.6924 - val_loss: 1.9367 - val_accuracy: 0.7986\n",
            "Epoch 132/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9761 - accuracy: 0.6804 - val_loss: 1.9916 - val_accuracy: 0.7904\n",
            "Epoch 133/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9829 - accuracy: 0.6844 - val_loss: 1.9467 - val_accuracy: 0.7980\n",
            "Epoch 134/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9671 - accuracy: 0.6858 - val_loss: 1.9763 - val_accuracy: 0.7835\n",
            "Epoch 135/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9809 - accuracy: 0.6818 - val_loss: 1.9531 - val_accuracy: 0.7999\n",
            "Epoch 136/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9786 - accuracy: 0.6850 - val_loss: 1.9577 - val_accuracy: 0.7967\n",
            "Epoch 137/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9805 - accuracy: 0.6856 - val_loss: 1.9836 - val_accuracy: 0.7955\n",
            "Epoch 138/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0194 - accuracy: 0.6780 - val_loss: 1.9773 - val_accuracy: 0.7961\n",
            "Epoch 139/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0117 - accuracy: 0.6881 - val_loss: 1.9630 - val_accuracy: 0.8037\n",
            "Epoch 140/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0319 - accuracy: 0.6839 - val_loss: 1.9817 - val_accuracy: 0.8018\n",
            "Epoch 141/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0232 - accuracy: 0.6768 - val_loss: 2.0491 - val_accuracy: 0.7708\n",
            "Epoch 142/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 2.0040 - accuracy: 0.6812 - val_loss: 2.0205 - val_accuracy: 0.7999\n",
            "Epoch 143/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 2.0124 - accuracy: 0.6827 - val_loss: 2.0023 - val_accuracy: 0.7910\n",
            "Epoch 144/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 2.0116 - accuracy: 0.6820 - val_loss: 1.9618 - val_accuracy: 0.7967\n",
            "Epoch 145/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9809 - accuracy: 0.6873 - val_loss: 1.9689 - val_accuracy: 0.7961\n",
            "Epoch 146/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 2.0101 - accuracy: 0.6812 - val_loss: 1.9941 - val_accuracy: 0.7955\n",
            "Epoch 147/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 2.0176 - accuracy: 0.6818 - val_loss: 1.9625 - val_accuracy: 0.7822\n",
            "Epoch 148/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9951 - accuracy: 0.6856 - val_loss: 1.9693 - val_accuracy: 0.7999\n",
            "Epoch 149/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9939 - accuracy: 0.6835 - val_loss: 1.9693 - val_accuracy: 0.7967\n",
            "Epoch 150/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9711 - accuracy: 0.6903 - val_loss: 1.9704 - val_accuracy: 0.7822\n",
            "Epoch 151/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9760 - accuracy: 0.6825 - val_loss: 1.9974 - val_accuracy: 0.7809\n",
            "Epoch 152/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9727 - accuracy: 0.6867 - val_loss: 1.9675 - val_accuracy: 0.7929\n",
            "Epoch 153/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9809 - accuracy: 0.6867 - val_loss: 2.0205 - val_accuracy: 0.8030\n",
            "Epoch 154/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9636 - accuracy: 0.6858 - val_loss: 1.9350 - val_accuracy: 0.8037\n",
            "Epoch 155/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9863 - accuracy: 0.6827 - val_loss: 1.9077 - val_accuracy: 0.8018\n",
            "Epoch 156/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9787 - accuracy: 0.6814 - val_loss: 1.9316 - val_accuracy: 0.8144\n",
            "Epoch 157/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9909 - accuracy: 0.6827 - val_loss: 1.9693 - val_accuracy: 0.8043\n",
            "Epoch 158/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9650 - accuracy: 0.6869 - val_loss: 1.9129 - val_accuracy: 0.8068\n",
            "Epoch 159/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9496 - accuracy: 0.6846 - val_loss: 1.9497 - val_accuracy: 0.7734\n",
            "Epoch 160/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9523 - accuracy: 0.6890 - val_loss: 1.9148 - val_accuracy: 0.7917\n",
            "Epoch 161/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9507 - accuracy: 0.6875 - val_loss: 1.9618 - val_accuracy: 0.8074\n",
            "Epoch 162/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9649 - accuracy: 0.6862 - val_loss: 1.9209 - val_accuracy: 0.7929\n",
            "Epoch 163/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9704 - accuracy: 0.6909 - val_loss: 1.9643 - val_accuracy: 0.7992\n",
            "Epoch 164/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.9789 - accuracy: 0.6772 - val_loss: 1.9864 - val_accuracy: 0.7809\n",
            "Epoch 165/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9673 - accuracy: 0.6850 - val_loss: 1.9488 - val_accuracy: 0.7986\n",
            "Epoch 166/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9638 - accuracy: 0.6890 - val_loss: 1.9602 - val_accuracy: 0.7967\n",
            "Epoch 167/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9598 - accuracy: 0.6877 - val_loss: 1.8942 - val_accuracy: 0.8011\n",
            "Epoch 168/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9393 - accuracy: 0.6896 - val_loss: 1.9516 - val_accuracy: 0.8112\n",
            "Epoch 169/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.9529 - accuracy: 0.6877 - val_loss: 1.9937 - val_accuracy: 0.7917\n",
            "Epoch 170/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9778 - accuracy: 0.6852 - val_loss: 1.9685 - val_accuracy: 0.7992\n",
            "Epoch 171/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9888 - accuracy: 0.6844 - val_loss: 1.9327 - val_accuracy: 0.8163\n",
            "Epoch 172/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9882 - accuracy: 0.6820 - val_loss: 1.9602 - val_accuracy: 0.7955\n",
            "Epoch 173/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9824 - accuracy: 0.6869 - val_loss: 1.9939 - val_accuracy: 0.8056\n",
            "Epoch 174/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9741 - accuracy: 0.6831 - val_loss: 1.9313 - val_accuracy: 0.8163\n",
            "Epoch 175/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9448 - accuracy: 0.6852 - val_loss: 1.9091 - val_accuracy: 0.7967\n",
            "Epoch 176/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9534 - accuracy: 0.6900 - val_loss: 1.9629 - val_accuracy: 0.7847\n",
            "Epoch 177/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9734 - accuracy: 0.6892 - val_loss: 2.0050 - val_accuracy: 0.7955\n",
            "Epoch 178/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9939 - accuracy: 0.6844 - val_loss: 1.9843 - val_accuracy: 0.8024\n",
            "Epoch 179/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9893 - accuracy: 0.6865 - val_loss: 1.9833 - val_accuracy: 0.7973\n",
            "Epoch 180/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9871 - accuracy: 0.6896 - val_loss: 1.9616 - val_accuracy: 0.7992\n",
            "Epoch 181/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9742 - accuracy: 0.6879 - val_loss: 1.9758 - val_accuracy: 0.8068\n",
            "Epoch 182/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9685 - accuracy: 0.6812 - val_loss: 1.9927 - val_accuracy: 0.7854\n",
            "Epoch 183/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9813 - accuracy: 0.6862 - val_loss: 1.9819 - val_accuracy: 0.7929\n",
            "Epoch 184/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9549 - accuracy: 0.6871 - val_loss: 1.9500 - val_accuracy: 0.7942\n",
            "Epoch 185/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9540 - accuracy: 0.6907 - val_loss: 1.9513 - val_accuracy: 0.7809\n",
            "Epoch 186/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9401 - accuracy: 0.6850 - val_loss: 1.9619 - val_accuracy: 0.7702\n",
            "Epoch 187/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9385 - accuracy: 0.6846 - val_loss: 1.9367 - val_accuracy: 0.7973\n",
            "Epoch 188/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9263 - accuracy: 0.6888 - val_loss: 1.9028 - val_accuracy: 0.8043\n",
            "Epoch 189/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9317 - accuracy: 0.6907 - val_loss: 1.9401 - val_accuracy: 0.8056\n",
            "Epoch 190/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9452 - accuracy: 0.6894 - val_loss: 2.0221 - val_accuracy: 0.8056\n",
            "Epoch 191/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9594 - accuracy: 0.6871 - val_loss: 1.9955 - val_accuracy: 0.7973\n",
            "Epoch 192/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9695 - accuracy: 0.6862 - val_loss: 1.9651 - val_accuracy: 0.8112\n",
            "Epoch 193/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9415 - accuracy: 0.6917 - val_loss: 1.9357 - val_accuracy: 0.8043\n",
            "Epoch 194/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9536 - accuracy: 0.6869 - val_loss: 1.9395 - val_accuracy: 0.7961\n",
            "Epoch 195/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9530 - accuracy: 0.6848 - val_loss: 1.9499 - val_accuracy: 0.8030\n",
            "Epoch 196/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9400 - accuracy: 0.6907 - val_loss: 1.9752 - val_accuracy: 0.8024\n",
            "Epoch 197/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9822 - accuracy: 0.6831 - val_loss: 1.9476 - val_accuracy: 0.8049\n",
            "Epoch 198/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9512 - accuracy: 0.6907 - val_loss: 1.9351 - val_accuracy: 0.8037\n",
            "Epoch 199/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9569 - accuracy: 0.6892 - val_loss: 1.9717 - val_accuracy: 0.7961\n",
            "Epoch 200/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9367 - accuracy: 0.6907 - val_loss: 1.9658 - val_accuracy: 0.8074\n",
            "Epoch 201/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9577 - accuracy: 0.6900 - val_loss: 1.9745 - val_accuracy: 0.8062\n",
            "Epoch 202/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9871 - accuracy: 0.6871 - val_loss: 1.9774 - val_accuracy: 0.7942\n",
            "Epoch 203/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9932 - accuracy: 0.6860 - val_loss: 1.9968 - val_accuracy: 0.7898\n",
            "Epoch 204/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9665 - accuracy: 0.6903 - val_loss: 1.9608 - val_accuracy: 0.8106\n",
            "Epoch 205/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9529 - accuracy: 0.6879 - val_loss: 1.9486 - val_accuracy: 0.8125\n",
            "Epoch 206/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9341 - accuracy: 0.6919 - val_loss: 1.9219 - val_accuracy: 0.8037\n",
            "Epoch 207/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9518 - accuracy: 0.6873 - val_loss: 1.9398 - val_accuracy: 0.8100\n",
            "Epoch 208/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 2.0055 - accuracy: 0.6860 - val_loss: 1.9967 - val_accuracy: 0.7986\n",
            "Epoch 209/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9570 - accuracy: 0.6940 - val_loss: 1.9767 - val_accuracy: 0.7980\n",
            "Epoch 210/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9513 - accuracy: 0.6873 - val_loss: 1.9521 - val_accuracy: 0.7929\n",
            "Epoch 211/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9413 - accuracy: 0.6905 - val_loss: 1.9384 - val_accuracy: 0.7992\n",
            "Epoch 212/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9650 - accuracy: 0.6909 - val_loss: 1.9730 - val_accuracy: 0.7942\n",
            "Epoch 213/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9441 - accuracy: 0.6938 - val_loss: 1.9311 - val_accuracy: 0.8100\n",
            "Epoch 214/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9355 - accuracy: 0.6894 - val_loss: 1.9405 - val_accuracy: 0.8106\n",
            "Epoch 215/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9410 - accuracy: 0.6943 - val_loss: 1.9594 - val_accuracy: 0.7948\n",
            "Epoch 216/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9600 - accuracy: 0.6879 - val_loss: 1.9752 - val_accuracy: 0.7980\n",
            "Epoch 217/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9467 - accuracy: 0.6869 - val_loss: 1.9388 - val_accuracy: 0.7910\n",
            "Epoch 218/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9188 - accuracy: 0.6907 - val_loss: 1.9311 - val_accuracy: 0.8011\n",
            "Epoch 219/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9440 - accuracy: 0.6879 - val_loss: 1.9247 - val_accuracy: 0.8081\n",
            "Epoch 220/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9449 - accuracy: 0.6900 - val_loss: 1.9412 - val_accuracy: 0.7992\n",
            "Epoch 221/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9372 - accuracy: 0.6890 - val_loss: 1.9149 - val_accuracy: 0.8106\n",
            "Epoch 222/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9021 - accuracy: 0.6959 - val_loss: 1.8951 - val_accuracy: 0.8049\n",
            "Epoch 223/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9086 - accuracy: 0.6926 - val_loss: 1.9021 - val_accuracy: 0.8024\n",
            "Epoch 224/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9147 - accuracy: 0.6900 - val_loss: 1.9680 - val_accuracy: 0.7910\n",
            "Epoch 225/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9358 - accuracy: 0.6928 - val_loss: 1.9268 - val_accuracy: 0.8062\n",
            "Epoch 226/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.9357 - accuracy: 0.6877 - val_loss: 1.9338 - val_accuracy: 0.8024\n",
            "Epoch 227/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9121 - accuracy: 0.6957 - val_loss: 2.0033 - val_accuracy: 0.7961\n",
            "Epoch 228/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9038 - accuracy: 0.6900 - val_loss: 1.9355 - val_accuracy: 0.8074\n",
            "Epoch 229/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9133 - accuracy: 0.6911 - val_loss: 1.9587 - val_accuracy: 0.8056\n",
            "Epoch 230/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9208 - accuracy: 0.6926 - val_loss: 1.9266 - val_accuracy: 0.8056\n",
            "Epoch 231/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.9222 - accuracy: 0.6921 - val_loss: 1.9230 - val_accuracy: 0.8125\n",
            "Epoch 232/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9271 - accuracy: 0.6898 - val_loss: 1.9205 - val_accuracy: 0.8106\n",
            "Epoch 233/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9111 - accuracy: 0.6898 - val_loss: 1.9362 - val_accuracy: 0.8011\n",
            "Epoch 234/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9188 - accuracy: 0.6892 - val_loss: 1.9322 - val_accuracy: 0.8011\n",
            "Epoch 235/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9266 - accuracy: 0.6898 - val_loss: 1.9002 - val_accuracy: 0.7923\n",
            "Epoch 236/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8982 - accuracy: 0.6888 - val_loss: 1.9398 - val_accuracy: 0.7986\n",
            "Epoch 237/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9149 - accuracy: 0.6936 - val_loss: 1.9164 - val_accuracy: 0.7992\n",
            "Epoch 238/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9247 - accuracy: 0.6913 - val_loss: 1.9823 - val_accuracy: 0.8024\n",
            "Epoch 239/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9225 - accuracy: 0.6949 - val_loss: 1.9262 - val_accuracy: 0.8005\n",
            "Epoch 240/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9035 - accuracy: 0.6940 - val_loss: 1.9226 - val_accuracy: 0.7986\n",
            "Epoch 241/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9032 - accuracy: 0.6909 - val_loss: 2.0533 - val_accuracy: 0.7961\n",
            "Epoch 242/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9185 - accuracy: 0.6894 - val_loss: 1.9720 - val_accuracy: 0.7973\n",
            "Epoch 243/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9132 - accuracy: 0.6976 - val_loss: 1.9054 - val_accuracy: 0.7929\n",
            "Epoch 244/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9013 - accuracy: 0.6936 - val_loss: 1.9371 - val_accuracy: 0.8106\n",
            "Epoch 245/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9240 - accuracy: 0.6877 - val_loss: 1.9150 - val_accuracy: 0.8093\n",
            "Epoch 246/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9295 - accuracy: 0.6926 - val_loss: 1.9351 - val_accuracy: 0.8018\n",
            "Epoch 247/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8828 - accuracy: 0.6993 - val_loss: 1.9195 - val_accuracy: 0.8068\n",
            "Epoch 248/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9288 - accuracy: 0.6877 - val_loss: 1.9471 - val_accuracy: 0.8150\n",
            "Epoch 249/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.9087 - accuracy: 0.6930 - val_loss: 1.8876 - val_accuracy: 0.8011\n",
            "Epoch 250/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9078 - accuracy: 0.6961 - val_loss: 1.9184 - val_accuracy: 0.7967\n",
            "Epoch 251/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8778 - accuracy: 0.6957 - val_loss: 1.9056 - val_accuracy: 0.8024\n",
            "Epoch 252/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8784 - accuracy: 0.6959 - val_loss: 1.8761 - val_accuracy: 0.8100\n",
            "Epoch 253/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.8868 - accuracy: 0.6943 - val_loss: 1.8770 - val_accuracy: 0.8074\n",
            "Epoch 254/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8851 - accuracy: 0.6949 - val_loss: 1.9713 - val_accuracy: 0.7816\n",
            "Epoch 255/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9132 - accuracy: 0.6938 - val_loss: 1.8929 - val_accuracy: 0.7986\n",
            "Epoch 256/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9081 - accuracy: 0.6884 - val_loss: 1.8770 - val_accuracy: 0.7904\n",
            "Epoch 257/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.9030 - accuracy: 0.6978 - val_loss: 1.8914 - val_accuracy: 0.8169\n",
            "Epoch 258/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9103 - accuracy: 0.6909 - val_loss: 1.8881 - val_accuracy: 0.8125\n",
            "Epoch 259/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8741 - accuracy: 0.6955 - val_loss: 1.8658 - val_accuracy: 0.8018\n",
            "Epoch 260/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8827 - accuracy: 0.6976 - val_loss: 1.9201 - val_accuracy: 0.7973\n",
            "Epoch 261/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9143 - accuracy: 0.6890 - val_loss: 1.9175 - val_accuracy: 0.8087\n",
            "Epoch 262/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.9112 - accuracy: 0.6951 - val_loss: 1.9217 - val_accuracy: 0.8037\n",
            "Epoch 263/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9109 - accuracy: 0.6947 - val_loss: 1.9036 - val_accuracy: 0.8100\n",
            "Epoch 264/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8887 - accuracy: 0.6970 - val_loss: 1.9210 - val_accuracy: 0.8043\n",
            "Epoch 265/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9209 - accuracy: 0.6917 - val_loss: 1.9216 - val_accuracy: 0.7891\n",
            "Epoch 266/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9106 - accuracy: 0.6875 - val_loss: 1.9128 - val_accuracy: 0.7955\n",
            "Epoch 267/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9243 - accuracy: 0.6934 - val_loss: 1.9226 - val_accuracy: 0.8150\n",
            "Epoch 268/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8991 - accuracy: 0.6957 - val_loss: 1.9065 - val_accuracy: 0.8100\n",
            "Epoch 269/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8995 - accuracy: 0.6907 - val_loss: 1.9305 - val_accuracy: 0.7967\n",
            "Epoch 270/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8835 - accuracy: 0.6974 - val_loss: 1.8785 - val_accuracy: 0.8081\n",
            "Epoch 271/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8717 - accuracy: 0.6976 - val_loss: 1.9028 - val_accuracy: 0.8011\n",
            "Epoch 272/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8799 - accuracy: 0.6970 - val_loss: 1.8686 - val_accuracy: 0.8068\n",
            "Epoch 273/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8811 - accuracy: 0.6951 - val_loss: 1.8850 - val_accuracy: 0.8163\n",
            "Epoch 274/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9057 - accuracy: 0.6913 - val_loss: 1.9290 - val_accuracy: 0.7910\n",
            "Epoch 275/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8951 - accuracy: 0.6949 - val_loss: 1.8979 - val_accuracy: 0.8068\n",
            "Epoch 276/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.9027 - accuracy: 0.6924 - val_loss: 1.9358 - val_accuracy: 0.8087\n",
            "Epoch 277/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8974 - accuracy: 0.7012 - val_loss: 1.9235 - val_accuracy: 0.8087\n",
            "Epoch 278/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8826 - accuracy: 0.6968 - val_loss: 1.8964 - val_accuracy: 0.8043\n",
            "Epoch 279/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9117 - accuracy: 0.6856 - val_loss: 1.8962 - val_accuracy: 0.8024\n",
            "Epoch 280/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.9252 - accuracy: 0.6886 - val_loss: 1.9345 - val_accuracy: 0.8081\n",
            "Epoch 281/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.9195 - accuracy: 0.6886 - val_loss: 1.9672 - val_accuracy: 0.7942\n",
            "Epoch 282/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8974 - accuracy: 0.6959 - val_loss: 1.9420 - val_accuracy: 0.8049\n",
            "Epoch 283/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8845 - accuracy: 0.6938 - val_loss: 1.9125 - val_accuracy: 0.7936\n",
            "Epoch 284/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8850 - accuracy: 0.6936 - val_loss: 1.9102 - val_accuracy: 0.8030\n",
            "Epoch 285/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.9222 - accuracy: 0.6924 - val_loss: 1.9244 - val_accuracy: 0.8106\n",
            "Epoch 286/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9005 - accuracy: 0.6915 - val_loss: 1.9236 - val_accuracy: 0.8037\n",
            "Epoch 287/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8915 - accuracy: 0.6957 - val_loss: 1.9283 - val_accuracy: 0.7948\n",
            "Epoch 288/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.9024 - accuracy: 0.6877 - val_loss: 1.9244 - val_accuracy: 0.8087\n",
            "Epoch 289/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8990 - accuracy: 0.6951 - val_loss: 1.8888 - val_accuracy: 0.8112\n",
            "Epoch 290/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8831 - accuracy: 0.6980 - val_loss: 1.8850 - val_accuracy: 0.8157\n",
            "Epoch 291/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8748 - accuracy: 0.7008 - val_loss: 1.8609 - val_accuracy: 0.8163\n",
            "Epoch 292/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8552 - accuracy: 0.6997 - val_loss: 1.8887 - val_accuracy: 0.7999\n",
            "Epoch 293/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8452 - accuracy: 0.7018 - val_loss: 1.8757 - val_accuracy: 0.8125\n",
            "Epoch 294/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8518 - accuracy: 0.7025 - val_loss: 1.8993 - val_accuracy: 0.8068\n",
            "Epoch 295/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8862 - accuracy: 0.6970 - val_loss: 1.8995 - val_accuracy: 0.8005\n",
            "Epoch 296/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8838 - accuracy: 0.6945 - val_loss: 1.8882 - val_accuracy: 0.8068\n",
            "Epoch 297/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.9107 - accuracy: 0.6881 - val_loss: 1.9305 - val_accuracy: 0.8024\n",
            "Epoch 298/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9058 - accuracy: 0.6953 - val_loss: 1.9032 - val_accuracy: 0.8119\n",
            "Epoch 299/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.9162 - accuracy: 0.6928 - val_loss: 1.9051 - val_accuracy: 0.7885\n",
            "Epoch 300/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.9060 - accuracy: 0.6947 - val_loss: 1.9358 - val_accuracy: 0.7967\n",
            "Epoch 301/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9250 - accuracy: 0.6871 - val_loss: 1.8799 - val_accuracy: 0.8068\n",
            "Epoch 302/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8860 - accuracy: 0.6978 - val_loss: 1.8891 - val_accuracy: 0.8030\n",
            "Epoch 303/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8772 - accuracy: 0.7001 - val_loss: 1.8725 - val_accuracy: 0.8074\n",
            "Epoch 304/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8656 - accuracy: 0.6987 - val_loss: 1.8718 - val_accuracy: 0.8049\n",
            "Epoch 305/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8710 - accuracy: 0.6966 - val_loss: 1.8870 - val_accuracy: 0.8176\n",
            "Epoch 306/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8748 - accuracy: 0.6949 - val_loss: 1.8956 - val_accuracy: 0.8018\n",
            "Epoch 307/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8582 - accuracy: 0.7008 - val_loss: 1.9069 - val_accuracy: 0.7948\n",
            "Epoch 308/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8692 - accuracy: 0.6972 - val_loss: 1.8675 - val_accuracy: 0.8213\n",
            "Epoch 309/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8596 - accuracy: 0.7027 - val_loss: 1.9099 - val_accuracy: 0.8144\n",
            "Epoch 310/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8449 - accuracy: 0.7006 - val_loss: 1.8482 - val_accuracy: 0.8005\n",
            "Epoch 311/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8586 - accuracy: 0.6957 - val_loss: 1.8930 - val_accuracy: 0.8049\n",
            "Epoch 312/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8896 - accuracy: 0.6985 - val_loss: 1.8944 - val_accuracy: 0.8011\n",
            "Epoch 313/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.8854 - accuracy: 0.6993 - val_loss: 1.9085 - val_accuracy: 0.7955\n",
            "Epoch 314/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.8832 - accuracy: 0.6997 - val_loss: 1.9094 - val_accuracy: 0.7999\n",
            "Epoch 315/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8684 - accuracy: 0.6936 - val_loss: 1.8724 - val_accuracy: 0.8081\n",
            "Epoch 316/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8657 - accuracy: 0.6966 - val_loss: 1.8476 - val_accuracy: 0.8119\n",
            "Epoch 317/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.8693 - accuracy: 0.7010 - val_loss: 1.8997 - val_accuracy: 0.8005\n",
            "Epoch 318/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8942 - accuracy: 0.6917 - val_loss: 1.9093 - val_accuracy: 0.8131\n",
            "Epoch 319/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8953 - accuracy: 0.6991 - val_loss: 1.8818 - val_accuracy: 0.8169\n",
            "Epoch 320/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8605 - accuracy: 0.6974 - val_loss: 1.8578 - val_accuracy: 0.8125\n",
            "Epoch 321/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8450 - accuracy: 0.6970 - val_loss: 1.8800 - val_accuracy: 0.8062\n",
            "Epoch 322/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8610 - accuracy: 0.6993 - val_loss: 1.8787 - val_accuracy: 0.8144\n",
            "Epoch 323/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8619 - accuracy: 0.6943 - val_loss: 1.8823 - val_accuracy: 0.8100\n",
            "Epoch 324/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8508 - accuracy: 0.6980 - val_loss: 1.8820 - val_accuracy: 0.8074\n",
            "Epoch 325/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8696 - accuracy: 0.6961 - val_loss: 1.9257 - val_accuracy: 0.7835\n",
            "Epoch 326/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8586 - accuracy: 0.6915 - val_loss: 1.8905 - val_accuracy: 0.7955\n",
            "Epoch 327/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8509 - accuracy: 0.6966 - val_loss: 1.9272 - val_accuracy: 0.7828\n",
            "Epoch 328/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8584 - accuracy: 0.6980 - val_loss: 1.8829 - val_accuracy: 0.8119\n",
            "Epoch 329/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.8527 - accuracy: 0.6970 - val_loss: 1.8990 - val_accuracy: 0.8018\n",
            "Epoch 330/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8927 - accuracy: 0.6913 - val_loss: 1.9026 - val_accuracy: 0.8068\n",
            "Epoch 331/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.8803 - accuracy: 0.6976 - val_loss: 1.8973 - val_accuracy: 0.7999\n",
            "Epoch 332/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.8741 - accuracy: 0.7018 - val_loss: 1.8658 - val_accuracy: 0.8030\n",
            "Epoch 333/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8758 - accuracy: 0.7008 - val_loss: 1.8592 - val_accuracy: 0.8194\n",
            "Epoch 334/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8606 - accuracy: 0.7012 - val_loss: 1.8653 - val_accuracy: 0.8125\n",
            "Epoch 335/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8629 - accuracy: 0.7035 - val_loss: 1.9141 - val_accuracy: 0.7992\n",
            "Epoch 336/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8681 - accuracy: 0.7031 - val_loss: 1.8800 - val_accuracy: 0.8201\n",
            "Epoch 337/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8657 - accuracy: 0.6961 - val_loss: 1.9662 - val_accuracy: 0.7910\n",
            "Epoch 338/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8551 - accuracy: 0.6919 - val_loss: 1.8731 - val_accuracy: 0.8049\n",
            "Epoch 339/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8497 - accuracy: 0.7014 - val_loss: 1.8546 - val_accuracy: 0.8005\n",
            "Epoch 340/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8423 - accuracy: 0.6928 - val_loss: 1.8630 - val_accuracy: 0.8150\n",
            "Epoch 341/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8438 - accuracy: 0.7035 - val_loss: 1.8895 - val_accuracy: 0.8182\n",
            "Epoch 342/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8505 - accuracy: 0.7029 - val_loss: 1.8724 - val_accuracy: 0.8037\n",
            "Epoch 343/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8185 - accuracy: 0.7018 - val_loss: 1.8637 - val_accuracy: 0.8030\n",
            "Epoch 344/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8432 - accuracy: 0.7037 - val_loss: 1.8833 - val_accuracy: 0.8074\n",
            "Epoch 345/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8538 - accuracy: 0.6961 - val_loss: 1.8627 - val_accuracy: 0.8018\n",
            "Epoch 346/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8637 - accuracy: 0.6976 - val_loss: 1.8535 - val_accuracy: 0.8119\n",
            "Epoch 347/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8364 - accuracy: 0.6970 - val_loss: 1.8506 - val_accuracy: 0.8062\n",
            "Epoch 348/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8503 - accuracy: 0.6940 - val_loss: 1.9159 - val_accuracy: 0.8049\n",
            "Epoch 349/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8445 - accuracy: 0.6978 - val_loss: 1.8951 - val_accuracy: 0.8068\n",
            "Epoch 350/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8365 - accuracy: 0.7054 - val_loss: 1.8960 - val_accuracy: 0.7917\n",
            "Epoch 351/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8537 - accuracy: 0.6997 - val_loss: 1.8781 - val_accuracy: 0.8081\n",
            "Epoch 352/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8353 - accuracy: 0.6995 - val_loss: 1.8834 - val_accuracy: 0.8213\n",
            "Epoch 353/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8365 - accuracy: 0.6976 - val_loss: 1.9107 - val_accuracy: 0.8049\n",
            "Epoch 354/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.9053 - accuracy: 0.6932 - val_loss: 1.8919 - val_accuracy: 0.8011\n",
            "Epoch 355/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8689 - accuracy: 0.6999 - val_loss: 1.8417 - val_accuracy: 0.8157\n",
            "Epoch 356/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8657 - accuracy: 0.7031 - val_loss: 1.8926 - val_accuracy: 0.8144\n",
            "Epoch 357/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8451 - accuracy: 0.7033 - val_loss: 1.8659 - val_accuracy: 0.8037\n",
            "Epoch 358/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8364 - accuracy: 0.7001 - val_loss: 1.8621 - val_accuracy: 0.8194\n",
            "Epoch 359/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8309 - accuracy: 0.7023 - val_loss: 1.8642 - val_accuracy: 0.7980\n",
            "Epoch 360/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8228 - accuracy: 0.7041 - val_loss: 1.8738 - val_accuracy: 0.8030\n",
            "Epoch 361/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8244 - accuracy: 0.7006 - val_loss: 1.8655 - val_accuracy: 0.8182\n",
            "Epoch 362/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8312 - accuracy: 0.7046 - val_loss: 1.8501 - val_accuracy: 0.8144\n",
            "Epoch 363/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8296 - accuracy: 0.7039 - val_loss: 1.8533 - val_accuracy: 0.8087\n",
            "Epoch 364/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8177 - accuracy: 0.7016 - val_loss: 1.8892 - val_accuracy: 0.8119\n",
            "Epoch 365/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8140 - accuracy: 0.7077 - val_loss: 1.8678 - val_accuracy: 0.8157\n",
            "Epoch 366/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8063 - accuracy: 0.7044 - val_loss: 1.8202 - val_accuracy: 0.8131\n",
            "Epoch 367/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8349 - accuracy: 0.6978 - val_loss: 1.8648 - val_accuracy: 0.8093\n",
            "Epoch 368/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8351 - accuracy: 0.7063 - val_loss: 1.8574 - val_accuracy: 0.8277\n",
            "Epoch 369/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8109 - accuracy: 0.6983 - val_loss: 1.8569 - val_accuracy: 0.8049\n",
            "Epoch 370/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8068 - accuracy: 0.7037 - val_loss: 1.8334 - val_accuracy: 0.8011\n",
            "Epoch 371/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8079 - accuracy: 0.7069 - val_loss: 1.8448 - val_accuracy: 0.7999\n",
            "Epoch 372/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8284 - accuracy: 0.7016 - val_loss: 1.8890 - val_accuracy: 0.7955\n",
            "Epoch 373/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8266 - accuracy: 0.7033 - val_loss: 1.8602 - val_accuracy: 0.8182\n",
            "Epoch 374/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8291 - accuracy: 0.6966 - val_loss: 1.8703 - val_accuracy: 0.8087\n",
            "Epoch 375/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8387 - accuracy: 0.7001 - val_loss: 1.8371 - val_accuracy: 0.8194\n",
            "Epoch 376/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8337 - accuracy: 0.6972 - val_loss: 1.9182 - val_accuracy: 0.8100\n",
            "Epoch 377/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8149 - accuracy: 0.7018 - val_loss: 1.8451 - val_accuracy: 0.8074\n",
            "Epoch 378/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8180 - accuracy: 0.7071 - val_loss: 1.8933 - val_accuracy: 0.8157\n",
            "Epoch 379/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8494 - accuracy: 0.6989 - val_loss: 1.8855 - val_accuracy: 0.8074\n",
            "Epoch 380/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8357 - accuracy: 0.7008 - val_loss: 1.8774 - val_accuracy: 0.8125\n",
            "Epoch 381/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8273 - accuracy: 0.7029 - val_loss: 1.8441 - val_accuracy: 0.8062\n",
            "Epoch 382/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8025 - accuracy: 0.7037 - val_loss: 1.9639 - val_accuracy: 0.8100\n",
            "Epoch 383/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8260 - accuracy: 0.7006 - val_loss: 1.8557 - val_accuracy: 0.8150\n",
            "Epoch 384/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8369 - accuracy: 0.7060 - val_loss: 1.8442 - val_accuracy: 0.8037\n",
            "Epoch 385/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8277 - accuracy: 0.7010 - val_loss: 1.8852 - val_accuracy: 0.8207\n",
            "Epoch 386/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8322 - accuracy: 0.7018 - val_loss: 1.8541 - val_accuracy: 0.8138\n",
            "Epoch 387/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8236 - accuracy: 0.6993 - val_loss: 1.8680 - val_accuracy: 0.8056\n",
            "Epoch 388/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.8398 - accuracy: 0.6987 - val_loss: 1.8437 - val_accuracy: 0.8138\n",
            "Epoch 389/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8198 - accuracy: 0.7052 - val_loss: 1.9000 - val_accuracy: 0.8037\n",
            "Epoch 390/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8408 - accuracy: 0.7033 - val_loss: 1.8670 - val_accuracy: 0.8024\n",
            "Epoch 391/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8331 - accuracy: 0.6985 - val_loss: 1.8369 - val_accuracy: 0.8049\n",
            "Epoch 392/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8498 - accuracy: 0.6936 - val_loss: 1.8601 - val_accuracy: 0.8081\n",
            "Epoch 393/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8238 - accuracy: 0.7008 - val_loss: 1.8506 - val_accuracy: 0.8188\n",
            "Epoch 394/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8114 - accuracy: 0.7105 - val_loss: 1.8362 - val_accuracy: 0.8093\n",
            "Epoch 395/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7879 - accuracy: 0.7092 - val_loss: 1.8275 - val_accuracy: 0.8232\n",
            "Epoch 396/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7968 - accuracy: 0.7071 - val_loss: 1.9046 - val_accuracy: 0.7961\n",
            "Epoch 397/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8189 - accuracy: 0.7001 - val_loss: 1.8606 - val_accuracy: 0.7973\n",
            "Epoch 398/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8215 - accuracy: 0.7006 - val_loss: 1.8586 - val_accuracy: 0.8220\n",
            "Epoch 399/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.8184 - accuracy: 0.6987 - val_loss: 1.8247 - val_accuracy: 0.8074\n",
            "Epoch 400/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8218 - accuracy: 0.7008 - val_loss: 1.8275 - val_accuracy: 0.8213\n",
            "Epoch 401/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7976 - accuracy: 0.7119 - val_loss: 1.8387 - val_accuracy: 0.8144\n",
            "Epoch 402/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8182 - accuracy: 0.7039 - val_loss: 1.8245 - val_accuracy: 0.8188\n",
            "Epoch 403/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8059 - accuracy: 0.7063 - val_loss: 1.8100 - val_accuracy: 0.8207\n",
            "Epoch 404/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7907 - accuracy: 0.7075 - val_loss: 1.8823 - val_accuracy: 0.8018\n",
            "Epoch 405/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8066 - accuracy: 0.7012 - val_loss: 1.8216 - val_accuracy: 0.8138\n",
            "Epoch 406/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8064 - accuracy: 0.7084 - val_loss: 1.8240 - val_accuracy: 0.8037\n",
            "Epoch 407/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8077 - accuracy: 0.6987 - val_loss: 1.8901 - val_accuracy: 0.8049\n",
            "Epoch 408/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8097 - accuracy: 0.7052 - val_loss: 1.8596 - val_accuracy: 0.8163\n",
            "Epoch 409/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8088 - accuracy: 0.6991 - val_loss: 1.8105 - val_accuracy: 0.8239\n",
            "Epoch 410/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8281 - accuracy: 0.7008 - val_loss: 1.8837 - val_accuracy: 0.8157\n",
            "Epoch 411/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8030 - accuracy: 0.7092 - val_loss: 1.8660 - val_accuracy: 0.8188\n",
            "Epoch 412/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.8210 - accuracy: 0.7012 - val_loss: 1.8404 - val_accuracy: 0.8074\n",
            "Epoch 413/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8193 - accuracy: 0.7033 - val_loss: 1.8421 - val_accuracy: 0.8226\n",
            "Epoch 414/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7941 - accuracy: 0.7081 - val_loss: 1.8482 - val_accuracy: 0.8157\n",
            "Epoch 415/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8240 - accuracy: 0.6974 - val_loss: 1.8415 - val_accuracy: 0.8176\n",
            "Epoch 416/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8193 - accuracy: 0.7071 - val_loss: 1.8462 - val_accuracy: 0.8176\n",
            "Epoch 417/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8095 - accuracy: 0.7031 - val_loss: 1.8561 - val_accuracy: 0.8093\n",
            "Epoch 418/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8103 - accuracy: 0.7027 - val_loss: 1.9494 - val_accuracy: 0.8100\n",
            "Epoch 419/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.8246 - accuracy: 0.7056 - val_loss: 1.8494 - val_accuracy: 0.8093\n",
            "Epoch 420/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8085 - accuracy: 0.7050 - val_loss: 1.8590 - val_accuracy: 0.8194\n",
            "Epoch 421/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8196 - accuracy: 0.6961 - val_loss: 1.8725 - val_accuracy: 0.8068\n",
            "Epoch 422/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7870 - accuracy: 0.7058 - val_loss: 1.8632 - val_accuracy: 0.7967\n",
            "Epoch 423/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7851 - accuracy: 0.7069 - val_loss: 1.8125 - val_accuracy: 0.8264\n",
            "Epoch 424/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7997 - accuracy: 0.7016 - val_loss: 1.8562 - val_accuracy: 0.8283\n",
            "Epoch 425/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7962 - accuracy: 0.7088 - val_loss: 1.8517 - val_accuracy: 0.8018\n",
            "Epoch 426/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8078 - accuracy: 0.7027 - val_loss: 1.8099 - val_accuracy: 0.8188\n",
            "Epoch 427/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7973 - accuracy: 0.7044 - val_loss: 1.8503 - val_accuracy: 0.8125\n",
            "Epoch 428/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7789 - accuracy: 0.7025 - val_loss: 1.8180 - val_accuracy: 0.8074\n",
            "Epoch 429/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7954 - accuracy: 0.7058 - val_loss: 1.8414 - val_accuracy: 0.8119\n",
            "Epoch 430/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.7806 - accuracy: 0.7090 - val_loss: 1.8576 - val_accuracy: 0.8018\n",
            "Epoch 431/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.8064 - accuracy: 0.7136 - val_loss: 1.8799 - val_accuracy: 0.7910\n",
            "Epoch 432/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7813 - accuracy: 0.7098 - val_loss: 1.8431 - val_accuracy: 0.8106\n",
            "Epoch 433/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7894 - accuracy: 0.7031 - val_loss: 1.8740 - val_accuracy: 0.8043\n",
            "Epoch 434/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7909 - accuracy: 0.7075 - val_loss: 1.8644 - val_accuracy: 0.7992\n",
            "Epoch 435/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7769 - accuracy: 0.7065 - val_loss: 1.8493 - val_accuracy: 0.8068\n",
            "Epoch 436/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7888 - accuracy: 0.7058 - val_loss: 1.8622 - val_accuracy: 0.8093\n",
            "Epoch 437/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7886 - accuracy: 0.7044 - val_loss: 1.8109 - val_accuracy: 0.8068\n",
            "Epoch 438/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8262 - accuracy: 0.7041 - val_loss: 1.8562 - val_accuracy: 0.8169\n",
            "Epoch 439/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7759 - accuracy: 0.7041 - val_loss: 1.8464 - val_accuracy: 0.8176\n",
            "Epoch 440/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7845 - accuracy: 0.7115 - val_loss: 1.8741 - val_accuracy: 0.8125\n",
            "Epoch 441/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7858 - accuracy: 0.7054 - val_loss: 1.8061 - val_accuracy: 0.8144\n",
            "Epoch 442/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8082 - accuracy: 0.7052 - val_loss: 1.8575 - val_accuracy: 0.8062\n",
            "Epoch 443/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7990 - accuracy: 0.7071 - val_loss: 1.8287 - val_accuracy: 0.8043\n",
            "Epoch 444/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7932 - accuracy: 0.7004 - val_loss: 1.8251 - val_accuracy: 0.8194\n",
            "Epoch 445/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.8003 - accuracy: 0.7077 - val_loss: 1.8764 - val_accuracy: 0.8232\n",
            "Epoch 446/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7918 - accuracy: 0.7086 - val_loss: 1.8387 - val_accuracy: 0.8112\n",
            "Epoch 447/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7721 - accuracy: 0.7124 - val_loss: 1.8065 - val_accuracy: 0.8018\n",
            "Epoch 448/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7752 - accuracy: 0.7115 - val_loss: 1.8040 - val_accuracy: 0.8157\n",
            "Epoch 449/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.8117 - accuracy: 0.6955 - val_loss: 1.8564 - val_accuracy: 0.8005\n",
            "Epoch 450/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7917 - accuracy: 0.7035 - val_loss: 1.8082 - val_accuracy: 0.8169\n",
            "Epoch 451/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7898 - accuracy: 0.7060 - val_loss: 1.8467 - val_accuracy: 0.8037\n",
            "Epoch 452/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7794 - accuracy: 0.7058 - val_loss: 1.8111 - val_accuracy: 0.8093\n",
            "Epoch 453/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7685 - accuracy: 0.7044 - val_loss: 1.8593 - val_accuracy: 0.8074\n",
            "Epoch 454/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7949 - accuracy: 0.7056 - val_loss: 1.8167 - val_accuracy: 0.8030\n",
            "Epoch 455/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7718 - accuracy: 0.7063 - val_loss: 1.8314 - val_accuracy: 0.8005\n",
            "Epoch 456/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7904 - accuracy: 0.7052 - val_loss: 1.8286 - val_accuracy: 0.8030\n",
            "Epoch 457/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7741 - accuracy: 0.7060 - val_loss: 1.8466 - val_accuracy: 0.8220\n",
            "Epoch 458/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7937 - accuracy: 0.6936 - val_loss: 1.8125 - val_accuracy: 0.8176\n",
            "Epoch 459/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7848 - accuracy: 0.7081 - val_loss: 1.8403 - val_accuracy: 0.8188\n",
            "Epoch 460/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7861 - accuracy: 0.7090 - val_loss: 1.8613 - val_accuracy: 0.8074\n",
            "Epoch 461/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7765 - accuracy: 0.7096 - val_loss: 1.8095 - val_accuracy: 0.8131\n",
            "Epoch 462/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7704 - accuracy: 0.7084 - val_loss: 1.8208 - val_accuracy: 0.8207\n",
            "Epoch 463/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7660 - accuracy: 0.7094 - val_loss: 1.8612 - val_accuracy: 0.7797\n",
            "Epoch 464/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7813 - accuracy: 0.7073 - val_loss: 1.8484 - val_accuracy: 0.8100\n",
            "Epoch 465/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7725 - accuracy: 0.7081 - val_loss: 1.8389 - val_accuracy: 0.7898\n",
            "Epoch 466/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7729 - accuracy: 0.7071 - val_loss: 1.8422 - val_accuracy: 0.8232\n",
            "Epoch 467/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7650 - accuracy: 0.7115 - val_loss: 1.8549 - val_accuracy: 0.8074\n",
            "Epoch 468/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7814 - accuracy: 0.7071 - val_loss: 1.8644 - val_accuracy: 0.7999\n",
            "Epoch 469/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7925 - accuracy: 0.7020 - val_loss: 1.8509 - val_accuracy: 0.8251\n",
            "Epoch 470/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7822 - accuracy: 0.7086 - val_loss: 1.8273 - val_accuracy: 0.8049\n",
            "Epoch 471/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7670 - accuracy: 0.7111 - val_loss: 1.9065 - val_accuracy: 0.8087\n",
            "Epoch 472/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7908 - accuracy: 0.7081 - val_loss: 1.8724 - val_accuracy: 0.8144\n",
            "Epoch 473/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7914 - accuracy: 0.7075 - val_loss: 1.8319 - val_accuracy: 0.8201\n",
            "Epoch 474/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7674 - accuracy: 0.7086 - val_loss: 1.8229 - val_accuracy: 0.8182\n",
            "Epoch 475/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7538 - accuracy: 0.7140 - val_loss: 1.8232 - val_accuracy: 0.8112\n",
            "Epoch 476/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7663 - accuracy: 0.7098 - val_loss: 1.8463 - val_accuracy: 0.8087\n",
            "Epoch 477/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7586 - accuracy: 0.7100 - val_loss: 1.9089 - val_accuracy: 0.8024\n",
            "Epoch 478/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7670 - accuracy: 0.7058 - val_loss: 1.8362 - val_accuracy: 0.8081\n",
            "Epoch 479/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7692 - accuracy: 0.7079 - val_loss: 1.8559 - val_accuracy: 0.8119\n",
            "Epoch 480/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7545 - accuracy: 0.7077 - val_loss: 1.8516 - val_accuracy: 0.8093\n",
            "Epoch 481/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7398 - accuracy: 0.7115 - val_loss: 1.7974 - val_accuracy: 0.8081\n",
            "Epoch 482/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7528 - accuracy: 0.7081 - val_loss: 1.7913 - val_accuracy: 0.8283\n",
            "Epoch 483/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7698 - accuracy: 0.7103 - val_loss: 1.8223 - val_accuracy: 0.8157\n",
            "Epoch 484/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7677 - accuracy: 0.7058 - val_loss: 1.8008 - val_accuracy: 0.8283\n",
            "Epoch 485/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7648 - accuracy: 0.7054 - val_loss: 1.8155 - val_accuracy: 0.8100\n",
            "Epoch 486/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7724 - accuracy: 0.7084 - val_loss: 1.8170 - val_accuracy: 0.8182\n",
            "Epoch 487/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7740 - accuracy: 0.7107 - val_loss: 1.8047 - val_accuracy: 0.8093\n",
            "Epoch 488/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7737 - accuracy: 0.7079 - val_loss: 1.7912 - val_accuracy: 0.8194\n",
            "Epoch 489/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7646 - accuracy: 0.7132 - val_loss: 1.8294 - val_accuracy: 0.8100\n",
            "Epoch 490/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7614 - accuracy: 0.7113 - val_loss: 1.8217 - val_accuracy: 0.8106\n",
            "Epoch 491/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7716 - accuracy: 0.7115 - val_loss: 1.7959 - val_accuracy: 0.8106\n",
            "Epoch 492/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7504 - accuracy: 0.7121 - val_loss: 1.8041 - val_accuracy: 0.8131\n",
            "Epoch 493/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7451 - accuracy: 0.7121 - val_loss: 1.8100 - val_accuracy: 0.8182\n",
            "Epoch 494/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7544 - accuracy: 0.7105 - val_loss: 1.8623 - val_accuracy: 0.7986\n",
            "Epoch 495/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7533 - accuracy: 0.7073 - val_loss: 1.8098 - val_accuracy: 0.7980\n",
            "Epoch 496/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7349 - accuracy: 0.7166 - val_loss: 1.8454 - val_accuracy: 0.8074\n",
            "Epoch 497/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7599 - accuracy: 0.7069 - val_loss: 1.7995 - val_accuracy: 0.8176\n",
            "Epoch 498/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7518 - accuracy: 0.7063 - val_loss: 1.8137 - val_accuracy: 0.8150\n",
            "Epoch 499/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7674 - accuracy: 0.7069 - val_loss: 1.8304 - val_accuracy: 0.8131\n",
            "Epoch 500/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7416 - accuracy: 0.7147 - val_loss: 1.8142 - val_accuracy: 0.8220\n",
            "Epoch 501/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7499 - accuracy: 0.7117 - val_loss: 1.8048 - val_accuracy: 0.8207\n",
            "Epoch 502/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7557 - accuracy: 0.7046 - val_loss: 1.8189 - val_accuracy: 0.8049\n",
            "Epoch 503/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7538 - accuracy: 0.7134 - val_loss: 1.8188 - val_accuracy: 0.8087\n",
            "Epoch 504/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7558 - accuracy: 0.7052 - val_loss: 1.8366 - val_accuracy: 0.8188\n",
            "Epoch 505/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7487 - accuracy: 0.7048 - val_loss: 1.8077 - val_accuracy: 0.8239\n",
            "Epoch 506/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7538 - accuracy: 0.7119 - val_loss: 1.8187 - val_accuracy: 0.8119\n",
            "Epoch 507/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7480 - accuracy: 0.7136 - val_loss: 1.8120 - val_accuracy: 0.8112\n",
            "Epoch 508/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7664 - accuracy: 0.7073 - val_loss: 1.8186 - val_accuracy: 0.8087\n",
            "Epoch 509/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7685 - accuracy: 0.7126 - val_loss: 1.8346 - val_accuracy: 0.8125\n",
            "Epoch 510/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7335 - accuracy: 0.7136 - val_loss: 1.7836 - val_accuracy: 0.8201\n",
            "Epoch 511/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7493 - accuracy: 0.7086 - val_loss: 1.8579 - val_accuracy: 0.8144\n",
            "Epoch 512/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7637 - accuracy: 0.7033 - val_loss: 1.8007 - val_accuracy: 0.8018\n",
            "Epoch 513/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7433 - accuracy: 0.7096 - val_loss: 1.8400 - val_accuracy: 0.8194\n",
            "Epoch 514/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.7408 - accuracy: 0.7136 - val_loss: 1.7998 - val_accuracy: 0.8226\n",
            "Epoch 515/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7441 - accuracy: 0.7075 - val_loss: 1.8020 - val_accuracy: 0.8157\n",
            "Epoch 516/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7480 - accuracy: 0.7130 - val_loss: 1.7763 - val_accuracy: 0.8264\n",
            "Epoch 517/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7377 - accuracy: 0.7065 - val_loss: 1.7832 - val_accuracy: 0.8270\n",
            "Epoch 518/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7326 - accuracy: 0.7132 - val_loss: 1.7937 - val_accuracy: 0.8226\n",
            "Epoch 519/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7419 - accuracy: 0.7071 - val_loss: 1.8146 - val_accuracy: 0.8188\n",
            "Epoch 520/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7553 - accuracy: 0.7054 - val_loss: 1.8447 - val_accuracy: 0.8081\n",
            "Epoch 521/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7489 - accuracy: 0.7096 - val_loss: 1.7762 - val_accuracy: 0.8245\n",
            "Epoch 522/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7430 - accuracy: 0.7100 - val_loss: 1.7745 - val_accuracy: 0.8264\n",
            "Epoch 523/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7509 - accuracy: 0.7100 - val_loss: 1.8029 - val_accuracy: 0.8207\n",
            "Epoch 524/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.7518 - accuracy: 0.7145 - val_loss: 1.7812 - val_accuracy: 0.8106\n",
            "Epoch 525/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7391 - accuracy: 0.7147 - val_loss: 1.7773 - val_accuracy: 0.8245\n",
            "Epoch 526/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7474 - accuracy: 0.7140 - val_loss: 1.8166 - val_accuracy: 0.8188\n",
            "Epoch 527/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7715 - accuracy: 0.7058 - val_loss: 1.8299 - val_accuracy: 0.8081\n",
            "Epoch 528/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7658 - accuracy: 0.7084 - val_loss: 1.7982 - val_accuracy: 0.8100\n",
            "Epoch 529/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7459 - accuracy: 0.7166 - val_loss: 1.8704 - val_accuracy: 0.8188\n",
            "Epoch 530/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7452 - accuracy: 0.7145 - val_loss: 1.8038 - val_accuracy: 0.8176\n",
            "Epoch 531/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7275 - accuracy: 0.7166 - val_loss: 1.7800 - val_accuracy: 0.8207\n",
            "Epoch 532/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.7323 - accuracy: 0.7153 - val_loss: 1.8138 - val_accuracy: 0.8176\n",
            "Epoch 533/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7355 - accuracy: 0.7081 - val_loss: 1.8243 - val_accuracy: 0.8106\n",
            "Epoch 534/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7289 - accuracy: 0.7119 - val_loss: 1.8284 - val_accuracy: 0.8119\n",
            "Epoch 535/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7511 - accuracy: 0.7105 - val_loss: 1.8085 - val_accuracy: 0.8043\n",
            "Epoch 536/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.7645 - accuracy: 0.7090 - val_loss: 1.8247 - val_accuracy: 0.8201\n",
            "Epoch 537/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7524 - accuracy: 0.7077 - val_loss: 1.7975 - val_accuracy: 0.8176\n",
            "Epoch 538/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7314 - accuracy: 0.7113 - val_loss: 1.8086 - val_accuracy: 0.8093\n",
            "Epoch 539/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7386 - accuracy: 0.7065 - val_loss: 1.8116 - val_accuracy: 0.8264\n",
            "Epoch 540/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7328 - accuracy: 0.7145 - val_loss: 1.8010 - val_accuracy: 0.8251\n",
            "Epoch 541/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7353 - accuracy: 0.7113 - val_loss: 1.8138 - val_accuracy: 0.8119\n",
            "Epoch 542/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7181 - accuracy: 0.7166 - val_loss: 1.7705 - val_accuracy: 0.8226\n",
            "Epoch 543/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7173 - accuracy: 0.7124 - val_loss: 1.7894 - val_accuracy: 0.8138\n",
            "Epoch 544/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7222 - accuracy: 0.7145 - val_loss: 1.7724 - val_accuracy: 0.8131\n",
            "Epoch 545/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7144 - accuracy: 0.7143 - val_loss: 1.7662 - val_accuracy: 0.8176\n",
            "Epoch 546/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7152 - accuracy: 0.7153 - val_loss: 1.7705 - val_accuracy: 0.8176\n",
            "Epoch 547/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7137 - accuracy: 0.7155 - val_loss: 1.7699 - val_accuracy: 0.8295\n",
            "Epoch 548/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7253 - accuracy: 0.7136 - val_loss: 1.7668 - val_accuracy: 0.8188\n",
            "Epoch 549/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7369 - accuracy: 0.7119 - val_loss: 1.8202 - val_accuracy: 0.8302\n",
            "Epoch 550/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7317 - accuracy: 0.7107 - val_loss: 1.7792 - val_accuracy: 0.8150\n",
            "Epoch 551/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7117 - accuracy: 0.7191 - val_loss: 1.8161 - val_accuracy: 0.7759\n",
            "Epoch 552/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7213 - accuracy: 0.7100 - val_loss: 1.7648 - val_accuracy: 0.8314\n",
            "Epoch 553/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7110 - accuracy: 0.7153 - val_loss: 1.7657 - val_accuracy: 0.8138\n",
            "Epoch 554/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7303 - accuracy: 0.7052 - val_loss: 1.8125 - val_accuracy: 0.8119\n",
            "Epoch 555/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7259 - accuracy: 0.7124 - val_loss: 1.7776 - val_accuracy: 0.8144\n",
            "Epoch 556/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7166 - accuracy: 0.7155 - val_loss: 1.8066 - val_accuracy: 0.8125\n",
            "Epoch 557/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7357 - accuracy: 0.7124 - val_loss: 1.8161 - val_accuracy: 0.8138\n",
            "Epoch 558/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7478 - accuracy: 0.7096 - val_loss: 1.8331 - val_accuracy: 0.8220\n",
            "Epoch 559/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7479 - accuracy: 0.7130 - val_loss: 1.8091 - val_accuracy: 0.8176\n",
            "Epoch 560/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7408 - accuracy: 0.7119 - val_loss: 1.7943 - val_accuracy: 0.8087\n",
            "Epoch 561/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7338 - accuracy: 0.7094 - val_loss: 1.7812 - val_accuracy: 0.8106\n",
            "Epoch 562/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7293 - accuracy: 0.7105 - val_loss: 1.7927 - val_accuracy: 0.8220\n",
            "Epoch 563/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7452 - accuracy: 0.7098 - val_loss: 1.7810 - val_accuracy: 0.8194\n",
            "Epoch 564/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7260 - accuracy: 0.7124 - val_loss: 1.8187 - val_accuracy: 0.8188\n",
            "Epoch 565/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7372 - accuracy: 0.7115 - val_loss: 1.7987 - val_accuracy: 0.8100\n",
            "Epoch 566/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7399 - accuracy: 0.7164 - val_loss: 1.8449 - val_accuracy: 0.8176\n",
            "Epoch 567/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7366 - accuracy: 0.7176 - val_loss: 1.7700 - val_accuracy: 0.8213\n",
            "Epoch 568/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7322 - accuracy: 0.7121 - val_loss: 1.8171 - val_accuracy: 0.8188\n",
            "Epoch 569/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7299 - accuracy: 0.7094 - val_loss: 1.8298 - val_accuracy: 0.8182\n",
            "Epoch 570/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7380 - accuracy: 0.7117 - val_loss: 1.8284 - val_accuracy: 0.8213\n",
            "Epoch 571/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7279 - accuracy: 0.7096 - val_loss: 1.8038 - val_accuracy: 0.8081\n",
            "Epoch 572/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7247 - accuracy: 0.7149 - val_loss: 1.8108 - val_accuracy: 0.8207\n",
            "Epoch 573/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7287 - accuracy: 0.7086 - val_loss: 1.8158 - val_accuracy: 0.8125\n",
            "Epoch 574/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7140 - accuracy: 0.7174 - val_loss: 1.7802 - val_accuracy: 0.8226\n",
            "Epoch 575/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7213 - accuracy: 0.7115 - val_loss: 1.8072 - val_accuracy: 0.8068\n",
            "Epoch 576/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7046 - accuracy: 0.7185 - val_loss: 1.7688 - val_accuracy: 0.8220\n",
            "Epoch 577/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7255 - accuracy: 0.7136 - val_loss: 1.7879 - val_accuracy: 0.8258\n",
            "Epoch 578/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7218 - accuracy: 0.7124 - val_loss: 1.7876 - val_accuracy: 0.8207\n",
            "Epoch 579/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7061 - accuracy: 0.7183 - val_loss: 1.7852 - val_accuracy: 0.8093\n",
            "Epoch 580/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7179 - accuracy: 0.7073 - val_loss: 1.7881 - val_accuracy: 0.8201\n",
            "Epoch 581/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7083 - accuracy: 0.7162 - val_loss: 1.7865 - val_accuracy: 0.8049\n",
            "Epoch 582/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7037 - accuracy: 0.7113 - val_loss: 1.7899 - val_accuracy: 0.8106\n",
            "Epoch 583/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7291 - accuracy: 0.7071 - val_loss: 1.7964 - val_accuracy: 0.8188\n",
            "Epoch 584/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7293 - accuracy: 0.7113 - val_loss: 1.7902 - val_accuracy: 0.8182\n",
            "Epoch 585/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6969 - accuracy: 0.7138 - val_loss: 1.7622 - val_accuracy: 0.8150\n",
            "Epoch 586/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7072 - accuracy: 0.7155 - val_loss: 1.8075 - val_accuracy: 0.8049\n",
            "Epoch 587/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7107 - accuracy: 0.7166 - val_loss: 1.7980 - val_accuracy: 0.8087\n",
            "Epoch 588/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7141 - accuracy: 0.7119 - val_loss: 1.7544 - val_accuracy: 0.8176\n",
            "Epoch 589/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6998 - accuracy: 0.7094 - val_loss: 1.7640 - val_accuracy: 0.8138\n",
            "Epoch 590/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7286 - accuracy: 0.7119 - val_loss: 1.8017 - val_accuracy: 0.8024\n",
            "Epoch 591/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6928 - accuracy: 0.7172 - val_loss: 1.7866 - val_accuracy: 0.8163\n",
            "Epoch 592/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7044 - accuracy: 0.7134 - val_loss: 1.8197 - val_accuracy: 0.8251\n",
            "Epoch 593/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7127 - accuracy: 0.7155 - val_loss: 1.7670 - val_accuracy: 0.8037\n",
            "Epoch 594/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7126 - accuracy: 0.7170 - val_loss: 1.8111 - val_accuracy: 0.8182\n",
            "Epoch 595/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7220 - accuracy: 0.7180 - val_loss: 1.7826 - val_accuracy: 0.8194\n",
            "Epoch 596/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7058 - accuracy: 0.7098 - val_loss: 1.7864 - val_accuracy: 0.8131\n",
            "Epoch 597/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7133 - accuracy: 0.7088 - val_loss: 1.7668 - val_accuracy: 0.8245\n",
            "Epoch 598/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7028 - accuracy: 0.7145 - val_loss: 1.8254 - val_accuracy: 0.8056\n",
            "Epoch 599/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7062 - accuracy: 0.7128 - val_loss: 1.7716 - val_accuracy: 0.8207\n",
            "Epoch 600/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6995 - accuracy: 0.7136 - val_loss: 1.7475 - val_accuracy: 0.8207\n",
            "Epoch 601/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7088 - accuracy: 0.7081 - val_loss: 1.7688 - val_accuracy: 0.8239\n",
            "Epoch 602/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6940 - accuracy: 0.7136 - val_loss: 1.7865 - val_accuracy: 0.8251\n",
            "Epoch 603/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7068 - accuracy: 0.7164 - val_loss: 1.7847 - val_accuracy: 0.8138\n",
            "Epoch 604/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7020 - accuracy: 0.7168 - val_loss: 1.7836 - val_accuracy: 0.8182\n",
            "Epoch 605/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6989 - accuracy: 0.7172 - val_loss: 1.8170 - val_accuracy: 0.7734\n",
            "Epoch 606/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7137 - accuracy: 0.7124 - val_loss: 1.7750 - val_accuracy: 0.8144\n",
            "Epoch 607/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7206 - accuracy: 0.7132 - val_loss: 1.7975 - val_accuracy: 0.8112\n",
            "Epoch 608/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.7064 - accuracy: 0.7138 - val_loss: 1.7851 - val_accuracy: 0.8131\n",
            "Epoch 609/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6956 - accuracy: 0.7185 - val_loss: 1.7698 - val_accuracy: 0.8213\n",
            "Epoch 610/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7013 - accuracy: 0.7077 - val_loss: 1.7658 - val_accuracy: 0.8157\n",
            "Epoch 611/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.6951 - accuracy: 0.7172 - val_loss: 1.7728 - val_accuracy: 0.8213\n",
            "Epoch 612/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7058 - accuracy: 0.7107 - val_loss: 1.7934 - val_accuracy: 0.8176\n",
            "Epoch 613/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7079 - accuracy: 0.7159 - val_loss: 1.7555 - val_accuracy: 0.8258\n",
            "Epoch 614/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.7057 - accuracy: 0.7170 - val_loss: 1.7993 - val_accuracy: 0.8112\n",
            "Epoch 615/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7083 - accuracy: 0.7121 - val_loss: 1.7340 - val_accuracy: 0.8169\n",
            "Epoch 616/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.7018 - accuracy: 0.7178 - val_loss: 1.7699 - val_accuracy: 0.8144\n",
            "Epoch 617/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6965 - accuracy: 0.7121 - val_loss: 1.7688 - val_accuracy: 0.8220\n",
            "Epoch 618/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6886 - accuracy: 0.7145 - val_loss: 1.7878 - val_accuracy: 0.8251\n",
            "Epoch 619/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7061 - accuracy: 0.7170 - val_loss: 1.7761 - val_accuracy: 0.8232\n",
            "Epoch 620/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7038 - accuracy: 0.7176 - val_loss: 1.7592 - val_accuracy: 0.8283\n",
            "Epoch 621/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6994 - accuracy: 0.7128 - val_loss: 1.8206 - val_accuracy: 0.7942\n",
            "Epoch 622/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7087 - accuracy: 0.7157 - val_loss: 1.7943 - val_accuracy: 0.8100\n",
            "Epoch 623/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6930 - accuracy: 0.7172 - val_loss: 1.7661 - val_accuracy: 0.8251\n",
            "Epoch 624/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6995 - accuracy: 0.7143 - val_loss: 1.7701 - val_accuracy: 0.8144\n",
            "Epoch 625/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6926 - accuracy: 0.7170 - val_loss: 1.7609 - val_accuracy: 0.8245\n",
            "Epoch 626/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6833 - accuracy: 0.7229 - val_loss: 1.7806 - val_accuracy: 0.8049\n",
            "Epoch 627/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6864 - accuracy: 0.7138 - val_loss: 1.7353 - val_accuracy: 0.8188\n",
            "Epoch 628/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6790 - accuracy: 0.7159 - val_loss: 1.7394 - val_accuracy: 0.8188\n",
            "Epoch 629/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6996 - accuracy: 0.7157 - val_loss: 1.7465 - val_accuracy: 0.8239\n",
            "Epoch 630/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.7182 - accuracy: 0.7117 - val_loss: 1.7925 - val_accuracy: 0.8245\n",
            "Epoch 631/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6986 - accuracy: 0.7176 - val_loss: 1.7643 - val_accuracy: 0.8157\n",
            "Epoch 632/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.7055 - accuracy: 0.7130 - val_loss: 1.7665 - val_accuracy: 0.8011\n",
            "Epoch 633/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6987 - accuracy: 0.7151 - val_loss: 1.7883 - val_accuracy: 0.8112\n",
            "Epoch 634/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6991 - accuracy: 0.7187 - val_loss: 1.7686 - val_accuracy: 0.8207\n",
            "Epoch 635/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6813 - accuracy: 0.7199 - val_loss: 1.8068 - val_accuracy: 0.7973\n",
            "Epoch 636/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.6955 - accuracy: 0.7081 - val_loss: 1.7788 - val_accuracy: 0.8220\n",
            "Epoch 637/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6916 - accuracy: 0.7128 - val_loss: 1.7932 - val_accuracy: 0.8131\n",
            "Epoch 638/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6935 - accuracy: 0.7136 - val_loss: 1.7982 - val_accuracy: 0.8270\n",
            "Epoch 639/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6888 - accuracy: 0.7153 - val_loss: 1.7521 - val_accuracy: 0.8226\n",
            "Epoch 640/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6765 - accuracy: 0.7155 - val_loss: 1.7163 - val_accuracy: 0.8213\n",
            "Epoch 641/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6841 - accuracy: 0.7151 - val_loss: 1.7641 - val_accuracy: 0.8176\n",
            "Epoch 642/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6849 - accuracy: 0.7195 - val_loss: 1.7787 - val_accuracy: 0.8157\n",
            "Epoch 643/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6747 - accuracy: 0.7195 - val_loss: 1.7733 - val_accuracy: 0.8232\n",
            "Epoch 644/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6967 - accuracy: 0.7115 - val_loss: 1.7731 - val_accuracy: 0.8100\n",
            "Epoch 645/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6951 - accuracy: 0.7191 - val_loss: 1.7691 - val_accuracy: 0.8163\n",
            "Epoch 646/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6746 - accuracy: 0.7189 - val_loss: 1.7445 - val_accuracy: 0.8163\n",
            "Epoch 647/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6768 - accuracy: 0.7166 - val_loss: 1.7456 - val_accuracy: 0.8176\n",
            "Epoch 648/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6855 - accuracy: 0.7151 - val_loss: 1.7620 - val_accuracy: 0.8245\n",
            "Epoch 649/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6625 - accuracy: 0.7176 - val_loss: 1.7383 - val_accuracy: 0.8201\n",
            "Epoch 650/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6887 - accuracy: 0.7143 - val_loss: 1.7415 - val_accuracy: 0.8213\n",
            "Epoch 651/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6807 - accuracy: 0.7263 - val_loss: 1.7741 - val_accuracy: 0.8005\n",
            "Epoch 652/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6907 - accuracy: 0.7113 - val_loss: 1.7539 - val_accuracy: 0.8106\n",
            "Epoch 653/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6852 - accuracy: 0.7164 - val_loss: 1.7746 - val_accuracy: 0.8131\n",
            "Epoch 654/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6918 - accuracy: 0.7204 - val_loss: 1.7851 - val_accuracy: 0.8283\n",
            "Epoch 655/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6966 - accuracy: 0.7107 - val_loss: 1.7878 - val_accuracy: 0.8264\n",
            "Epoch 656/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6796 - accuracy: 0.7208 - val_loss: 1.7640 - val_accuracy: 0.8176\n",
            "Epoch 657/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6888 - accuracy: 0.7124 - val_loss: 1.7466 - val_accuracy: 0.8258\n",
            "Epoch 658/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6782 - accuracy: 0.7157 - val_loss: 1.7705 - val_accuracy: 0.8283\n",
            "Epoch 659/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6812 - accuracy: 0.7195 - val_loss: 1.7480 - val_accuracy: 0.8213\n",
            "Epoch 660/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6826 - accuracy: 0.7100 - val_loss: 1.7421 - val_accuracy: 0.8245\n",
            "Epoch 661/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.6863 - accuracy: 0.7229 - val_loss: 1.8137 - val_accuracy: 0.8213\n",
            "Epoch 662/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6971 - accuracy: 0.7145 - val_loss: 1.8315 - val_accuracy: 0.8100\n",
            "Epoch 663/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6820 - accuracy: 0.7218 - val_loss: 1.7517 - val_accuracy: 0.8340\n",
            "Epoch 664/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6761 - accuracy: 0.7140 - val_loss: 1.7606 - val_accuracy: 0.8169\n",
            "Epoch 665/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6833 - accuracy: 0.7180 - val_loss: 1.7660 - val_accuracy: 0.8169\n",
            "Epoch 666/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.6931 - accuracy: 0.7138 - val_loss: 1.7829 - val_accuracy: 0.8176\n",
            "Epoch 667/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6782 - accuracy: 0.7172 - val_loss: 1.7669 - val_accuracy: 0.8125\n",
            "Epoch 668/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6710 - accuracy: 0.7178 - val_loss: 1.7607 - val_accuracy: 0.8207\n",
            "Epoch 669/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6826 - accuracy: 0.7218 - val_loss: 1.7518 - val_accuracy: 0.8232\n",
            "Epoch 670/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6827 - accuracy: 0.7199 - val_loss: 1.7505 - val_accuracy: 0.8295\n",
            "Epoch 671/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6813 - accuracy: 0.7275 - val_loss: 1.7722 - val_accuracy: 0.8245\n",
            "Epoch 672/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6858 - accuracy: 0.7109 - val_loss: 1.7674 - val_accuracy: 0.8125\n",
            "Epoch 673/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6672 - accuracy: 0.7157 - val_loss: 1.7397 - val_accuracy: 0.8289\n",
            "Epoch 674/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6642 - accuracy: 0.7239 - val_loss: 1.7477 - val_accuracy: 0.8327\n",
            "Epoch 675/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6820 - accuracy: 0.7145 - val_loss: 1.7587 - val_accuracy: 0.8213\n",
            "Epoch 676/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6736 - accuracy: 0.7168 - val_loss: 1.7772 - val_accuracy: 0.8131\n",
            "Epoch 677/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6808 - accuracy: 0.7130 - val_loss: 1.7485 - val_accuracy: 0.8201\n",
            "Epoch 678/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6619 - accuracy: 0.7317 - val_loss: 1.7779 - val_accuracy: 0.8194\n",
            "Epoch 679/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6709 - accuracy: 0.7237 - val_loss: 1.7616 - val_accuracy: 0.8258\n",
            "Epoch 680/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6781 - accuracy: 0.7174 - val_loss: 1.7591 - val_accuracy: 0.8163\n",
            "Epoch 681/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6702 - accuracy: 0.7271 - val_loss: 1.7768 - val_accuracy: 0.8194\n",
            "Epoch 682/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6810 - accuracy: 0.7178 - val_loss: 1.7809 - val_accuracy: 0.8188\n",
            "Epoch 683/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6723 - accuracy: 0.7202 - val_loss: 1.7506 - val_accuracy: 0.8220\n",
            "Epoch 684/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6577 - accuracy: 0.7258 - val_loss: 1.7870 - val_accuracy: 0.8138\n",
            "Epoch 685/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6778 - accuracy: 0.7113 - val_loss: 1.7609 - val_accuracy: 0.8087\n",
            "Epoch 686/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6531 - accuracy: 0.7263 - val_loss: 1.8295 - val_accuracy: 0.8125\n",
            "Epoch 687/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6895 - accuracy: 0.7107 - val_loss: 1.7813 - val_accuracy: 0.8112\n",
            "Epoch 688/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6635 - accuracy: 0.7235 - val_loss: 1.7480 - val_accuracy: 0.8245\n",
            "Epoch 689/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6623 - accuracy: 0.7140 - val_loss: 1.7625 - val_accuracy: 0.8220\n",
            "Epoch 690/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6660 - accuracy: 0.7225 - val_loss: 1.7020 - val_accuracy: 0.8359\n",
            "Epoch 691/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6664 - accuracy: 0.7172 - val_loss: 1.7535 - val_accuracy: 0.8176\n",
            "Epoch 692/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6772 - accuracy: 0.7191 - val_loss: 1.7296 - val_accuracy: 0.8188\n",
            "Epoch 693/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6819 - accuracy: 0.7183 - val_loss: 1.7822 - val_accuracy: 0.8226\n",
            "Epoch 694/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6909 - accuracy: 0.7237 - val_loss: 1.7432 - val_accuracy: 0.8302\n",
            "Epoch 695/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6835 - accuracy: 0.7157 - val_loss: 1.7730 - val_accuracy: 0.8182\n",
            "Epoch 696/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6814 - accuracy: 0.7159 - val_loss: 1.7500 - val_accuracy: 0.8308\n",
            "Epoch 697/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6712 - accuracy: 0.7185 - val_loss: 1.7785 - val_accuracy: 0.8131\n",
            "Epoch 698/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6613 - accuracy: 0.7199 - val_loss: 1.7268 - val_accuracy: 0.8194\n",
            "Epoch 699/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6573 - accuracy: 0.7136 - val_loss: 1.7773 - val_accuracy: 0.8138\n",
            "Epoch 700/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6573 - accuracy: 0.7197 - val_loss: 1.7275 - val_accuracy: 0.8201\n",
            "Epoch 701/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6504 - accuracy: 0.7199 - val_loss: 1.7607 - val_accuracy: 0.8232\n",
            "Epoch 702/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6615 - accuracy: 0.7145 - val_loss: 1.7330 - val_accuracy: 0.8188\n",
            "Epoch 703/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6415 - accuracy: 0.7237 - val_loss: 1.7222 - val_accuracy: 0.8226\n",
            "Epoch 704/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6530 - accuracy: 0.7231 - val_loss: 1.7499 - val_accuracy: 0.8245\n",
            "Epoch 705/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6542 - accuracy: 0.7191 - val_loss: 1.8168 - val_accuracy: 0.8163\n",
            "Epoch 706/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.6548 - accuracy: 0.7254 - val_loss: 1.7378 - val_accuracy: 0.8220\n",
            "Epoch 707/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6550 - accuracy: 0.7178 - val_loss: 1.7660 - val_accuracy: 0.8188\n",
            "Epoch 708/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6486 - accuracy: 0.7237 - val_loss: 1.7433 - val_accuracy: 0.8106\n",
            "Epoch 709/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6504 - accuracy: 0.7229 - val_loss: 1.7609 - val_accuracy: 0.8106\n",
            "Epoch 710/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6568 - accuracy: 0.7202 - val_loss: 1.7253 - val_accuracy: 0.8220\n",
            "Epoch 711/1000\n",
            "149/149 [==============================] - 4s 29ms/step - loss: 1.6565 - accuracy: 0.7178 - val_loss: 1.8036 - val_accuracy: 0.8100\n",
            "Epoch 712/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6823 - accuracy: 0.7153 - val_loss: 1.7479 - val_accuracy: 0.8226\n",
            "Epoch 713/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6670 - accuracy: 0.7216 - val_loss: 1.7425 - val_accuracy: 0.8074\n",
            "Epoch 714/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6600 - accuracy: 0.7231 - val_loss: 1.7366 - val_accuracy: 0.8176\n",
            "Epoch 715/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6565 - accuracy: 0.7225 - val_loss: 1.7262 - val_accuracy: 0.8176\n",
            "Epoch 716/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6702 - accuracy: 0.7216 - val_loss: 1.7315 - val_accuracy: 0.8213\n",
            "Epoch 717/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6592 - accuracy: 0.7178 - val_loss: 1.7474 - val_accuracy: 0.8169\n",
            "Epoch 718/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6408 - accuracy: 0.7254 - val_loss: 1.7371 - val_accuracy: 0.8226\n",
            "Epoch 719/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6521 - accuracy: 0.7189 - val_loss: 1.7123 - val_accuracy: 0.8201\n",
            "Epoch 720/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6412 - accuracy: 0.7212 - val_loss: 1.7203 - val_accuracy: 0.8207\n",
            "Epoch 721/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6501 - accuracy: 0.7159 - val_loss: 1.7522 - val_accuracy: 0.8314\n",
            "Epoch 722/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6485 - accuracy: 0.7229 - val_loss: 1.7273 - val_accuracy: 0.8340\n",
            "Epoch 723/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6690 - accuracy: 0.7183 - val_loss: 1.7363 - val_accuracy: 0.8163\n",
            "Epoch 724/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6820 - accuracy: 0.7242 - val_loss: 1.7610 - val_accuracy: 0.8093\n",
            "Epoch 725/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6537 - accuracy: 0.7183 - val_loss: 1.7762 - val_accuracy: 0.8169\n",
            "Epoch 726/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6590 - accuracy: 0.7220 - val_loss: 1.7566 - val_accuracy: 0.8093\n",
            "Epoch 727/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6639 - accuracy: 0.7147 - val_loss: 1.7475 - val_accuracy: 0.8295\n",
            "Epoch 728/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6598 - accuracy: 0.7193 - val_loss: 1.7648 - val_accuracy: 0.8182\n",
            "Epoch 729/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6681 - accuracy: 0.7115 - val_loss: 1.8048 - val_accuracy: 0.8157\n",
            "Epoch 730/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6802 - accuracy: 0.7206 - val_loss: 1.7566 - val_accuracy: 0.8157\n",
            "Epoch 731/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6627 - accuracy: 0.7162 - val_loss: 1.7985 - val_accuracy: 0.8131\n",
            "Epoch 732/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6579 - accuracy: 0.7258 - val_loss: 1.7897 - val_accuracy: 0.8201\n",
            "Epoch 733/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6492 - accuracy: 0.7235 - val_loss: 1.7630 - val_accuracy: 0.8239\n",
            "Epoch 734/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6567 - accuracy: 0.7168 - val_loss: 1.7412 - val_accuracy: 0.8150\n",
            "Epoch 735/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6457 - accuracy: 0.7229 - val_loss: 1.7964 - val_accuracy: 0.8049\n",
            "Epoch 736/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6592 - accuracy: 0.7195 - val_loss: 1.7527 - val_accuracy: 0.8176\n",
            "Epoch 737/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6457 - accuracy: 0.7157 - val_loss: 1.7711 - val_accuracy: 0.8150\n",
            "Epoch 738/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6648 - accuracy: 0.7227 - val_loss: 1.7747 - val_accuracy: 0.8188\n",
            "Epoch 739/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6500 - accuracy: 0.7214 - val_loss: 1.7182 - val_accuracy: 0.8258\n",
            "Epoch 740/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6436 - accuracy: 0.7218 - val_loss: 1.7499 - val_accuracy: 0.8258\n",
            "Epoch 741/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6675 - accuracy: 0.7164 - val_loss: 1.7515 - val_accuracy: 0.8270\n",
            "Epoch 742/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6481 - accuracy: 0.7197 - val_loss: 1.7797 - val_accuracy: 0.8125\n",
            "Epoch 743/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6327 - accuracy: 0.7223 - val_loss: 1.7578 - val_accuracy: 0.8277\n",
            "Epoch 744/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6519 - accuracy: 0.7206 - val_loss: 1.7611 - val_accuracy: 0.8112\n",
            "Epoch 745/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6346 - accuracy: 0.7269 - val_loss: 1.7721 - val_accuracy: 0.8251\n",
            "Epoch 746/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6588 - accuracy: 0.7172 - val_loss: 1.6999 - val_accuracy: 0.8270\n",
            "Epoch 747/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6444 - accuracy: 0.7237 - val_loss: 1.7639 - val_accuracy: 0.8011\n",
            "Epoch 748/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6368 - accuracy: 0.7284 - val_loss: 1.7515 - val_accuracy: 0.8239\n",
            "Epoch 749/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6442 - accuracy: 0.7244 - val_loss: 1.7174 - val_accuracy: 0.8321\n",
            "Epoch 750/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6331 - accuracy: 0.7220 - val_loss: 1.7043 - val_accuracy: 0.8226\n",
            "Epoch 751/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6560 - accuracy: 0.7164 - val_loss: 1.7068 - val_accuracy: 0.8327\n",
            "Epoch 752/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6387 - accuracy: 0.7223 - val_loss: 1.7392 - val_accuracy: 0.8289\n",
            "Epoch 753/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6454 - accuracy: 0.7220 - val_loss: 1.7144 - val_accuracy: 0.8220\n",
            "Epoch 754/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6725 - accuracy: 0.7107 - val_loss: 1.7503 - val_accuracy: 0.8327\n",
            "Epoch 755/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6540 - accuracy: 0.7252 - val_loss: 1.7415 - val_accuracy: 0.8207\n",
            "Epoch 756/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6615 - accuracy: 0.7162 - val_loss: 1.7458 - val_accuracy: 0.8226\n",
            "Epoch 757/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6370 - accuracy: 0.7239 - val_loss: 1.7693 - val_accuracy: 0.8226\n",
            "Epoch 758/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6454 - accuracy: 0.7229 - val_loss: 1.7698 - val_accuracy: 0.8207\n",
            "Epoch 759/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6353 - accuracy: 0.7252 - val_loss: 1.7464 - val_accuracy: 0.8182\n",
            "Epoch 760/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6414 - accuracy: 0.7227 - val_loss: 1.7350 - val_accuracy: 0.8176\n",
            "Epoch 761/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6352 - accuracy: 0.7271 - val_loss: 1.7526 - val_accuracy: 0.8043\n",
            "Epoch 762/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6223 - accuracy: 0.7282 - val_loss: 1.7027 - val_accuracy: 0.8220\n",
            "Epoch 763/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6421 - accuracy: 0.7220 - val_loss: 1.7189 - val_accuracy: 0.8365\n",
            "Epoch 764/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6319 - accuracy: 0.7279 - val_loss: 1.7349 - val_accuracy: 0.8226\n",
            "Epoch 765/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6387 - accuracy: 0.7191 - val_loss: 1.7351 - val_accuracy: 0.8321\n",
            "Epoch 766/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6214 - accuracy: 0.7248 - val_loss: 1.7140 - val_accuracy: 0.8213\n",
            "Epoch 767/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6429 - accuracy: 0.7229 - val_loss: 1.7264 - val_accuracy: 0.8182\n",
            "Epoch 768/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6458 - accuracy: 0.7210 - val_loss: 1.7152 - val_accuracy: 0.8258\n",
            "Epoch 769/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6453 - accuracy: 0.7178 - val_loss: 1.7307 - val_accuracy: 0.8277\n",
            "Epoch 770/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6438 - accuracy: 0.7189 - val_loss: 1.7530 - val_accuracy: 0.8074\n",
            "Epoch 771/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6395 - accuracy: 0.7298 - val_loss: 1.7796 - val_accuracy: 0.8201\n",
            "Epoch 772/1000\n",
            "149/149 [==============================] - 5s 35ms/step - loss: 1.6287 - accuracy: 0.7250 - val_loss: 1.7791 - val_accuracy: 0.8100\n",
            "Epoch 773/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6362 - accuracy: 0.7199 - val_loss: 1.7279 - val_accuracy: 0.8213\n",
            "Epoch 774/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6128 - accuracy: 0.7263 - val_loss: 1.7250 - val_accuracy: 0.7955\n",
            "Epoch 775/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6402 - accuracy: 0.7269 - val_loss: 1.7365 - val_accuracy: 0.8201\n",
            "Epoch 776/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6378 - accuracy: 0.7233 - val_loss: 1.7694 - val_accuracy: 0.8239\n",
            "Epoch 777/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6332 - accuracy: 0.7208 - val_loss: 1.7027 - val_accuracy: 0.8277\n",
            "Epoch 778/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6210 - accuracy: 0.7292 - val_loss: 1.7402 - val_accuracy: 0.8213\n",
            "Epoch 779/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6149 - accuracy: 0.7294 - val_loss: 1.7388 - val_accuracy: 0.8169\n",
            "Epoch 780/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6354 - accuracy: 0.7189 - val_loss: 1.7292 - val_accuracy: 0.8239\n",
            "Epoch 781/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6085 - accuracy: 0.7288 - val_loss: 1.7171 - val_accuracy: 0.8251\n",
            "Epoch 782/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6249 - accuracy: 0.7244 - val_loss: 1.7487 - val_accuracy: 0.8188\n",
            "Epoch 783/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6230 - accuracy: 0.7227 - val_loss: 1.7153 - val_accuracy: 0.8327\n",
            "Epoch 784/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6133 - accuracy: 0.7229 - val_loss: 1.7366 - val_accuracy: 0.8289\n",
            "Epoch 785/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6213 - accuracy: 0.7210 - val_loss: 1.7150 - val_accuracy: 0.8201\n",
            "Epoch 786/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6275 - accuracy: 0.7206 - val_loss: 1.7136 - val_accuracy: 0.8270\n",
            "Epoch 787/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6282 - accuracy: 0.7246 - val_loss: 1.7173 - val_accuracy: 0.8251\n",
            "Epoch 788/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6278 - accuracy: 0.7246 - val_loss: 1.7081 - val_accuracy: 0.8371\n",
            "Epoch 789/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6340 - accuracy: 0.7208 - val_loss: 1.7178 - val_accuracy: 0.8340\n",
            "Epoch 790/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6481 - accuracy: 0.7151 - val_loss: 1.7142 - val_accuracy: 0.8188\n",
            "Epoch 791/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6292 - accuracy: 0.7191 - val_loss: 1.7474 - val_accuracy: 0.8258\n",
            "Epoch 792/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6232 - accuracy: 0.7229 - val_loss: 1.7746 - val_accuracy: 0.8150\n",
            "Epoch 793/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6274 - accuracy: 0.7258 - val_loss: 1.7145 - val_accuracy: 0.8106\n",
            "Epoch 794/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6199 - accuracy: 0.7300 - val_loss: 1.7067 - val_accuracy: 0.8340\n",
            "Epoch 795/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6268 - accuracy: 0.7172 - val_loss: 1.7164 - val_accuracy: 0.8270\n",
            "Epoch 796/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6238 - accuracy: 0.7210 - val_loss: 1.7194 - val_accuracy: 0.8258\n",
            "Epoch 797/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6220 - accuracy: 0.7248 - val_loss: 1.7283 - val_accuracy: 0.8207\n",
            "Epoch 798/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6234 - accuracy: 0.7242 - val_loss: 1.7012 - val_accuracy: 0.8176\n",
            "Epoch 799/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6199 - accuracy: 0.7269 - val_loss: 1.7066 - val_accuracy: 0.8220\n",
            "Epoch 800/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6087 - accuracy: 0.7322 - val_loss: 1.7175 - val_accuracy: 0.8194\n",
            "Epoch 801/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6252 - accuracy: 0.7176 - val_loss: 1.7190 - val_accuracy: 0.8245\n",
            "Epoch 802/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6149 - accuracy: 0.7206 - val_loss: 1.7258 - val_accuracy: 0.8188\n",
            "Epoch 803/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6173 - accuracy: 0.7195 - val_loss: 1.7183 - val_accuracy: 0.8213\n",
            "Epoch 804/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6169 - accuracy: 0.7277 - val_loss: 1.7073 - val_accuracy: 0.8144\n",
            "Epoch 805/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6254 - accuracy: 0.7286 - val_loss: 1.7199 - val_accuracy: 0.8232\n",
            "Epoch 806/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6137 - accuracy: 0.7220 - val_loss: 1.7289 - val_accuracy: 0.8207\n",
            "Epoch 807/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6194 - accuracy: 0.7214 - val_loss: 1.6973 - val_accuracy: 0.8314\n",
            "Epoch 808/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6121 - accuracy: 0.7218 - val_loss: 1.7356 - val_accuracy: 0.8327\n",
            "Epoch 809/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6335 - accuracy: 0.7172 - val_loss: 1.7552 - val_accuracy: 0.8131\n",
            "Epoch 810/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6212 - accuracy: 0.7260 - val_loss: 1.7333 - val_accuracy: 0.8277\n",
            "Epoch 811/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6094 - accuracy: 0.7292 - val_loss: 1.7318 - val_accuracy: 0.8213\n",
            "Epoch 812/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6061 - accuracy: 0.7319 - val_loss: 1.7121 - val_accuracy: 0.8239\n",
            "Epoch 813/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6135 - accuracy: 0.7282 - val_loss: 1.6973 - val_accuracy: 0.8251\n",
            "Epoch 814/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6046 - accuracy: 0.7277 - val_loss: 1.7246 - val_accuracy: 0.8277\n",
            "Epoch 815/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.6203 - accuracy: 0.7223 - val_loss: 1.6965 - val_accuracy: 0.8283\n",
            "Epoch 816/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6218 - accuracy: 0.7250 - val_loss: 1.7220 - val_accuracy: 0.8258\n",
            "Epoch 817/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6201 - accuracy: 0.7202 - val_loss: 1.7523 - val_accuracy: 0.8163\n",
            "Epoch 818/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6200 - accuracy: 0.7269 - val_loss: 1.7458 - val_accuracy: 0.8239\n",
            "Epoch 819/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6266 - accuracy: 0.7252 - val_loss: 1.7423 - val_accuracy: 0.8264\n",
            "Epoch 820/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6177 - accuracy: 0.7254 - val_loss: 1.7595 - val_accuracy: 0.8289\n",
            "Epoch 821/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6200 - accuracy: 0.7206 - val_loss: 1.7297 - val_accuracy: 0.8163\n",
            "Epoch 822/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6048 - accuracy: 0.7269 - val_loss: 1.7033 - val_accuracy: 0.8295\n",
            "Epoch 823/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6339 - accuracy: 0.7216 - val_loss: 1.7088 - val_accuracy: 0.8295\n",
            "Epoch 824/1000\n",
            "149/149 [==============================] - 4s 30ms/step - loss: 1.6246 - accuracy: 0.7183 - val_loss: 1.7379 - val_accuracy: 0.8194\n",
            "Epoch 825/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6119 - accuracy: 0.7225 - val_loss: 1.7233 - val_accuracy: 0.8213\n",
            "Epoch 826/1000\n",
            "149/149 [==============================] - 5s 35ms/step - loss: 1.6219 - accuracy: 0.7212 - val_loss: 1.7048 - val_accuracy: 0.8213\n",
            "Epoch 827/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6096 - accuracy: 0.7235 - val_loss: 1.7034 - val_accuracy: 0.8207\n",
            "Epoch 828/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6277 - accuracy: 0.7126 - val_loss: 1.7460 - val_accuracy: 0.8264\n",
            "Epoch 829/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6173 - accuracy: 0.7294 - val_loss: 1.7262 - val_accuracy: 0.8074\n",
            "Epoch 830/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6075 - accuracy: 0.7248 - val_loss: 1.7074 - val_accuracy: 0.8062\n",
            "Epoch 831/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6229 - accuracy: 0.7204 - val_loss: 1.7210 - val_accuracy: 0.8157\n",
            "Epoch 832/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6087 - accuracy: 0.7227 - val_loss: 1.7229 - val_accuracy: 0.8232\n",
            "Epoch 833/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6121 - accuracy: 0.7229 - val_loss: 1.6987 - val_accuracy: 0.8251\n",
            "Epoch 834/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6054 - accuracy: 0.7218 - val_loss: 1.7379 - val_accuracy: 0.8239\n",
            "Epoch 835/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6096 - accuracy: 0.7212 - val_loss: 1.7248 - val_accuracy: 0.8302\n",
            "Epoch 836/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5939 - accuracy: 0.7309 - val_loss: 1.7025 - val_accuracy: 0.8277\n",
            "Epoch 837/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5977 - accuracy: 0.7269 - val_loss: 1.6836 - val_accuracy: 0.8378\n",
            "Epoch 838/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6018 - accuracy: 0.7260 - val_loss: 1.7148 - val_accuracy: 0.8201\n",
            "Epoch 839/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5968 - accuracy: 0.7250 - val_loss: 1.7159 - val_accuracy: 0.8182\n",
            "Epoch 840/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6081 - accuracy: 0.7250 - val_loss: 1.7122 - val_accuracy: 0.8327\n",
            "Epoch 841/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6027 - accuracy: 0.7298 - val_loss: 1.7445 - val_accuracy: 0.8188\n",
            "Epoch 842/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6188 - accuracy: 0.7220 - val_loss: 1.7431 - val_accuracy: 0.8213\n",
            "Epoch 843/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.6060 - accuracy: 0.7265 - val_loss: 1.7418 - val_accuracy: 0.8188\n",
            "Epoch 844/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6021 - accuracy: 0.7239 - val_loss: 1.7184 - val_accuracy: 0.8289\n",
            "Epoch 845/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6024 - accuracy: 0.7284 - val_loss: 1.7071 - val_accuracy: 0.8213\n",
            "Epoch 846/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6051 - accuracy: 0.7248 - val_loss: 1.7123 - val_accuracy: 0.8232\n",
            "Epoch 847/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6090 - accuracy: 0.7256 - val_loss: 1.7042 - val_accuracy: 0.8245\n",
            "Epoch 848/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5930 - accuracy: 0.7271 - val_loss: 1.7249 - val_accuracy: 0.8226\n",
            "Epoch 849/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.5942 - accuracy: 0.7273 - val_loss: 1.7278 - val_accuracy: 0.8150\n",
            "Epoch 850/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5989 - accuracy: 0.7303 - val_loss: 1.7066 - val_accuracy: 0.8213\n",
            "Epoch 851/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.6100 - accuracy: 0.7258 - val_loss: 1.7084 - val_accuracy: 0.8112\n",
            "Epoch 852/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6109 - accuracy: 0.7220 - val_loss: 1.7132 - val_accuracy: 0.8226\n",
            "Epoch 853/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6072 - accuracy: 0.7208 - val_loss: 1.7018 - val_accuracy: 0.8112\n",
            "Epoch 854/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.5953 - accuracy: 0.7260 - val_loss: 1.7001 - val_accuracy: 0.8396\n",
            "Epoch 855/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5879 - accuracy: 0.7250 - val_loss: 1.7311 - val_accuracy: 0.8207\n",
            "Epoch 856/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6069 - accuracy: 0.7252 - val_loss: 1.7004 - val_accuracy: 0.8100\n",
            "Epoch 857/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5941 - accuracy: 0.7298 - val_loss: 1.7254 - val_accuracy: 0.8226\n",
            "Epoch 858/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5986 - accuracy: 0.7298 - val_loss: 1.7263 - val_accuracy: 0.8283\n",
            "Epoch 859/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5942 - accuracy: 0.7263 - val_loss: 1.7141 - val_accuracy: 0.8277\n",
            "Epoch 860/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6014 - accuracy: 0.7292 - val_loss: 1.7420 - val_accuracy: 0.8220\n",
            "Epoch 861/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5929 - accuracy: 0.7271 - val_loss: 1.7086 - val_accuracy: 0.8314\n",
            "Epoch 862/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6142 - accuracy: 0.7227 - val_loss: 1.7398 - val_accuracy: 0.8226\n",
            "Epoch 863/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.6035 - accuracy: 0.7313 - val_loss: 1.6989 - val_accuracy: 0.8264\n",
            "Epoch 864/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6057 - accuracy: 0.7269 - val_loss: 1.7163 - val_accuracy: 0.8295\n",
            "Epoch 865/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5948 - accuracy: 0.7254 - val_loss: 1.7117 - val_accuracy: 0.8163\n",
            "Epoch 866/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6099 - accuracy: 0.7208 - val_loss: 1.7243 - val_accuracy: 0.8188\n",
            "Epoch 867/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5851 - accuracy: 0.7324 - val_loss: 1.7274 - val_accuracy: 0.8043\n",
            "Epoch 868/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5873 - accuracy: 0.7317 - val_loss: 1.7148 - val_accuracy: 0.8277\n",
            "Epoch 869/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5863 - accuracy: 0.7319 - val_loss: 1.6962 - val_accuracy: 0.8245\n",
            "Epoch 870/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5841 - accuracy: 0.7298 - val_loss: 1.6941 - val_accuracy: 0.8277\n",
            "Epoch 871/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5983 - accuracy: 0.7227 - val_loss: 1.7262 - val_accuracy: 0.8207\n",
            "Epoch 872/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5917 - accuracy: 0.7336 - val_loss: 1.6957 - val_accuracy: 0.8277\n",
            "Epoch 873/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6001 - accuracy: 0.7242 - val_loss: 1.7160 - val_accuracy: 0.8239\n",
            "Epoch 874/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5963 - accuracy: 0.7309 - val_loss: 1.6848 - val_accuracy: 0.8264\n",
            "Epoch 875/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5900 - accuracy: 0.7206 - val_loss: 1.6877 - val_accuracy: 0.8340\n",
            "Epoch 876/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5926 - accuracy: 0.7246 - val_loss: 1.7599 - val_accuracy: 0.8226\n",
            "Epoch 877/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5981 - accuracy: 0.7324 - val_loss: 1.7144 - val_accuracy: 0.8226\n",
            "Epoch 878/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.6021 - accuracy: 0.7214 - val_loss: 1.6823 - val_accuracy: 0.8333\n",
            "Epoch 879/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5900 - accuracy: 0.7220 - val_loss: 1.7278 - val_accuracy: 0.8163\n",
            "Epoch 880/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5951 - accuracy: 0.7233 - val_loss: 1.7042 - val_accuracy: 0.8245\n",
            "Epoch 881/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5901 - accuracy: 0.7279 - val_loss: 1.7350 - val_accuracy: 0.8176\n",
            "Epoch 882/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5922 - accuracy: 0.7294 - val_loss: 1.6892 - val_accuracy: 0.8371\n",
            "Epoch 883/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5884 - accuracy: 0.7328 - val_loss: 1.7066 - val_accuracy: 0.8333\n",
            "Epoch 884/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5929 - accuracy: 0.7252 - val_loss: 1.7159 - val_accuracy: 0.8150\n",
            "Epoch 885/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5898 - accuracy: 0.7271 - val_loss: 1.7069 - val_accuracy: 0.8251\n",
            "Epoch 886/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5847 - accuracy: 0.7288 - val_loss: 1.6915 - val_accuracy: 0.8422\n",
            "Epoch 887/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5844 - accuracy: 0.7263 - val_loss: 1.6903 - val_accuracy: 0.8226\n",
            "Epoch 888/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5844 - accuracy: 0.7271 - val_loss: 1.7241 - val_accuracy: 0.8207\n",
            "Epoch 889/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5754 - accuracy: 0.7340 - val_loss: 1.6984 - val_accuracy: 0.8245\n",
            "Epoch 890/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5859 - accuracy: 0.7292 - val_loss: 1.7079 - val_accuracy: 0.8207\n",
            "Epoch 891/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5882 - accuracy: 0.7267 - val_loss: 1.6916 - val_accuracy: 0.8232\n",
            "Epoch 892/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5886 - accuracy: 0.7307 - val_loss: 1.7146 - val_accuracy: 0.8295\n",
            "Epoch 893/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.6044 - accuracy: 0.7212 - val_loss: 1.7084 - val_accuracy: 0.8277\n",
            "Epoch 894/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6078 - accuracy: 0.7197 - val_loss: 1.7139 - val_accuracy: 0.8188\n",
            "Epoch 895/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.6005 - accuracy: 0.7218 - val_loss: 1.7241 - val_accuracy: 0.8283\n",
            "Epoch 896/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.6014 - accuracy: 0.7288 - val_loss: 1.7579 - val_accuracy: 0.8182\n",
            "Epoch 897/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.6040 - accuracy: 0.7248 - val_loss: 1.7243 - val_accuracy: 0.8270\n",
            "Epoch 898/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5933 - accuracy: 0.7286 - val_loss: 1.6949 - val_accuracy: 0.8264\n",
            "Epoch 899/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5804 - accuracy: 0.7292 - val_loss: 1.6889 - val_accuracy: 0.8270\n",
            "Epoch 900/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5922 - accuracy: 0.7233 - val_loss: 1.7196 - val_accuracy: 0.8333\n",
            "Epoch 901/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5904 - accuracy: 0.7279 - val_loss: 1.7007 - val_accuracy: 0.8283\n",
            "Epoch 902/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5849 - accuracy: 0.7260 - val_loss: 1.7193 - val_accuracy: 0.8163\n",
            "Epoch 903/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5815 - accuracy: 0.7307 - val_loss: 1.6830 - val_accuracy: 0.8359\n",
            "Epoch 904/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5742 - accuracy: 0.7292 - val_loss: 1.7117 - val_accuracy: 0.8232\n",
            "Epoch 905/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5799 - accuracy: 0.7275 - val_loss: 1.6885 - val_accuracy: 0.8264\n",
            "Epoch 906/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5774 - accuracy: 0.7267 - val_loss: 1.6855 - val_accuracy: 0.8321\n",
            "Epoch 907/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5855 - accuracy: 0.7282 - val_loss: 1.7102 - val_accuracy: 0.8068\n",
            "Epoch 908/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5780 - accuracy: 0.7267 - val_loss: 1.7026 - val_accuracy: 0.8131\n",
            "Epoch 909/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5860 - accuracy: 0.7246 - val_loss: 1.7006 - val_accuracy: 0.8226\n",
            "Epoch 910/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5795 - accuracy: 0.7288 - val_loss: 1.7027 - val_accuracy: 0.8308\n",
            "Epoch 911/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5833 - accuracy: 0.7288 - val_loss: 1.6650 - val_accuracy: 0.8378\n",
            "Epoch 912/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5930 - accuracy: 0.7277 - val_loss: 1.7030 - val_accuracy: 0.8283\n",
            "Epoch 913/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5772 - accuracy: 0.7298 - val_loss: 1.7083 - val_accuracy: 0.8182\n",
            "Epoch 914/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5735 - accuracy: 0.7286 - val_loss: 1.7228 - val_accuracy: 0.8093\n",
            "Epoch 915/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5740 - accuracy: 0.7328 - val_loss: 1.6858 - val_accuracy: 0.8277\n",
            "Epoch 916/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5749 - accuracy: 0.7294 - val_loss: 1.7036 - val_accuracy: 0.8201\n",
            "Epoch 917/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5744 - accuracy: 0.7305 - val_loss: 1.7007 - val_accuracy: 0.8333\n",
            "Epoch 918/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5810 - accuracy: 0.7258 - val_loss: 1.6870 - val_accuracy: 0.8277\n",
            "Epoch 919/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5841 - accuracy: 0.7324 - val_loss: 1.6808 - val_accuracy: 0.8314\n",
            "Epoch 920/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5757 - accuracy: 0.7216 - val_loss: 1.7213 - val_accuracy: 0.8207\n",
            "Epoch 921/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5782 - accuracy: 0.7237 - val_loss: 1.6789 - val_accuracy: 0.8428\n",
            "Epoch 922/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.5749 - accuracy: 0.7271 - val_loss: 1.7172 - val_accuracy: 0.7948\n",
            "Epoch 923/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5790 - accuracy: 0.7271 - val_loss: 1.6958 - val_accuracy: 0.8226\n",
            "Epoch 924/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5713 - accuracy: 0.7260 - val_loss: 1.6890 - val_accuracy: 0.8264\n",
            "Epoch 925/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5684 - accuracy: 0.7319 - val_loss: 1.6803 - val_accuracy: 0.8239\n",
            "Epoch 926/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5696 - accuracy: 0.7242 - val_loss: 1.6800 - val_accuracy: 0.8245\n",
            "Epoch 927/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5773 - accuracy: 0.7300 - val_loss: 1.6785 - val_accuracy: 0.8321\n",
            "Epoch 928/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5888 - accuracy: 0.7258 - val_loss: 1.7031 - val_accuracy: 0.8277\n",
            "Epoch 929/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5701 - accuracy: 0.7235 - val_loss: 1.7001 - val_accuracy: 0.8207\n",
            "Epoch 930/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5787 - accuracy: 0.7282 - val_loss: 1.7469 - val_accuracy: 0.8062\n",
            "Epoch 931/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5880 - accuracy: 0.7263 - val_loss: 1.7136 - val_accuracy: 0.8163\n",
            "Epoch 932/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5952 - accuracy: 0.7290 - val_loss: 1.7029 - val_accuracy: 0.8239\n",
            "Epoch 933/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5860 - accuracy: 0.7271 - val_loss: 1.7001 - val_accuracy: 0.8207\n",
            "Epoch 934/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5797 - accuracy: 0.7254 - val_loss: 1.6985 - val_accuracy: 0.8289\n",
            "Epoch 935/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5643 - accuracy: 0.7260 - val_loss: 1.7031 - val_accuracy: 0.8207\n",
            "Epoch 936/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5731 - accuracy: 0.7265 - val_loss: 1.6841 - val_accuracy: 0.8239\n",
            "Epoch 937/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5763 - accuracy: 0.7288 - val_loss: 1.7212 - val_accuracy: 0.8194\n",
            "Epoch 938/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5805 - accuracy: 0.7290 - val_loss: 1.6963 - val_accuracy: 0.8194\n",
            "Epoch 939/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5778 - accuracy: 0.7260 - val_loss: 1.6861 - val_accuracy: 0.8258\n",
            "Epoch 940/1000\n",
            "149/149 [==============================] - 5s 35ms/step - loss: 1.5753 - accuracy: 0.7237 - val_loss: 1.7108 - val_accuracy: 0.8245\n",
            "Epoch 941/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5613 - accuracy: 0.7260 - val_loss: 1.6860 - val_accuracy: 0.8314\n",
            "Epoch 942/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5691 - accuracy: 0.7267 - val_loss: 1.7068 - val_accuracy: 0.8239\n",
            "Epoch 943/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5692 - accuracy: 0.7284 - val_loss: 1.6976 - val_accuracy: 0.8163\n",
            "Epoch 944/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5593 - accuracy: 0.7277 - val_loss: 1.6988 - val_accuracy: 0.8245\n",
            "Epoch 945/1000\n",
            "149/149 [==============================] - 5s 35ms/step - loss: 1.5612 - accuracy: 0.7288 - val_loss: 1.7141 - val_accuracy: 0.8213\n",
            "Epoch 946/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5790 - accuracy: 0.7271 - val_loss: 1.7332 - val_accuracy: 0.8150\n",
            "Epoch 947/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5779 - accuracy: 0.7265 - val_loss: 1.7252 - val_accuracy: 0.8106\n",
            "Epoch 948/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5711 - accuracy: 0.7319 - val_loss: 1.7129 - val_accuracy: 0.8201\n",
            "Epoch 949/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5743 - accuracy: 0.7300 - val_loss: 1.6947 - val_accuracy: 0.8239\n",
            "Epoch 950/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5695 - accuracy: 0.7309 - val_loss: 1.7014 - val_accuracy: 0.8314\n",
            "Epoch 951/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5779 - accuracy: 0.7277 - val_loss: 1.7026 - val_accuracy: 0.8283\n",
            "Epoch 952/1000\n",
            "149/149 [==============================] - 5s 35ms/step - loss: 1.5693 - accuracy: 0.7279 - val_loss: 1.6771 - val_accuracy: 0.8289\n",
            "Epoch 953/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5654 - accuracy: 0.7326 - val_loss: 1.6742 - val_accuracy: 0.8283\n",
            "Epoch 954/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5711 - accuracy: 0.7279 - val_loss: 1.6988 - val_accuracy: 0.8270\n",
            "Epoch 955/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5621 - accuracy: 0.7269 - val_loss: 1.7084 - val_accuracy: 0.8232\n",
            "Epoch 956/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5791 - accuracy: 0.7260 - val_loss: 1.7232 - val_accuracy: 0.8163\n",
            "Epoch 957/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5674 - accuracy: 0.7313 - val_loss: 1.6737 - val_accuracy: 0.8314\n",
            "Epoch 958/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5625 - accuracy: 0.7311 - val_loss: 1.6963 - val_accuracy: 0.8277\n",
            "Epoch 959/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5722 - accuracy: 0.7311 - val_loss: 1.6889 - val_accuracy: 0.8239\n",
            "Epoch 960/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5684 - accuracy: 0.7328 - val_loss: 1.6906 - val_accuracy: 0.8239\n",
            "Epoch 961/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5541 - accuracy: 0.7351 - val_loss: 1.6831 - val_accuracy: 0.8194\n",
            "Epoch 962/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5571 - accuracy: 0.7263 - val_loss: 1.6914 - val_accuracy: 0.8188\n",
            "Epoch 963/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5562 - accuracy: 0.7330 - val_loss: 1.6701 - val_accuracy: 0.8378\n",
            "Epoch 964/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5531 - accuracy: 0.7263 - val_loss: 1.6822 - val_accuracy: 0.8251\n",
            "Epoch 965/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5688 - accuracy: 0.7353 - val_loss: 1.6992 - val_accuracy: 0.8283\n",
            "Epoch 966/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5634 - accuracy: 0.7317 - val_loss: 1.6940 - val_accuracy: 0.8176\n",
            "Epoch 967/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5623 - accuracy: 0.7330 - val_loss: 1.6989 - val_accuracy: 0.8283\n",
            "Epoch 968/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5614 - accuracy: 0.7279 - val_loss: 1.6990 - val_accuracy: 0.8327\n",
            "Epoch 969/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5745 - accuracy: 0.7290 - val_loss: 1.7135 - val_accuracy: 0.8258\n",
            "Epoch 970/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5708 - accuracy: 0.7351 - val_loss: 1.6839 - val_accuracy: 0.8264\n",
            "Epoch 971/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5775 - accuracy: 0.7256 - val_loss: 1.6718 - val_accuracy: 0.8365\n",
            "Epoch 972/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5694 - accuracy: 0.7277 - val_loss: 1.6924 - val_accuracy: 0.8194\n",
            "Epoch 973/1000\n",
            "149/149 [==============================] - 5s 30ms/step - loss: 1.5648 - accuracy: 0.7284 - val_loss: 1.7021 - val_accuracy: 0.8157\n",
            "Epoch 974/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5619 - accuracy: 0.7307 - val_loss: 1.6897 - val_accuracy: 0.8213\n",
            "Epoch 975/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5500 - accuracy: 0.7319 - val_loss: 1.6673 - val_accuracy: 0.8251\n",
            "Epoch 976/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5584 - accuracy: 0.7319 - val_loss: 1.6879 - val_accuracy: 0.8169\n",
            "Epoch 977/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5654 - accuracy: 0.7263 - val_loss: 1.6961 - val_accuracy: 0.8220\n",
            "Epoch 978/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5633 - accuracy: 0.7288 - val_loss: 1.6731 - val_accuracy: 0.8207\n",
            "Epoch 979/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5510 - accuracy: 0.7351 - val_loss: 1.7195 - val_accuracy: 0.8081\n",
            "Epoch 980/1000\n",
            "149/149 [==============================] - 5s 35ms/step - loss: 1.5680 - accuracy: 0.7340 - val_loss: 1.6827 - val_accuracy: 0.8251\n",
            "Epoch 981/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5518 - accuracy: 0.7292 - val_loss: 1.6924 - val_accuracy: 0.8270\n",
            "Epoch 982/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5536 - accuracy: 0.7366 - val_loss: 1.6946 - val_accuracy: 0.8093\n",
            "Epoch 983/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5500 - accuracy: 0.7347 - val_loss: 1.6978 - val_accuracy: 0.8321\n",
            "Epoch 984/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5529 - accuracy: 0.7311 - val_loss: 1.6790 - val_accuracy: 0.8220\n",
            "Epoch 985/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5487 - accuracy: 0.7307 - val_loss: 1.7221 - val_accuracy: 0.8277\n",
            "Epoch 986/1000\n",
            "149/149 [==============================] - 5s 33ms/step - loss: 1.5568 - accuracy: 0.7338 - val_loss: 1.6867 - val_accuracy: 0.8194\n",
            "Epoch 987/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5636 - accuracy: 0.7309 - val_loss: 1.6725 - val_accuracy: 0.8258\n",
            "Epoch 988/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5520 - accuracy: 0.7300 - val_loss: 1.7055 - val_accuracy: 0.8321\n",
            "Epoch 989/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5520 - accuracy: 0.7313 - val_loss: 1.6883 - val_accuracy: 0.8289\n",
            "Epoch 990/1000\n",
            "149/149 [==============================] - 5s 35ms/step - loss: 1.5514 - accuracy: 0.7319 - val_loss: 1.6859 - val_accuracy: 0.8321\n",
            "Epoch 991/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5507 - accuracy: 0.7355 - val_loss: 1.6835 - val_accuracy: 0.8302\n",
            "Epoch 992/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5533 - accuracy: 0.7303 - val_loss: 1.7206 - val_accuracy: 0.8245\n",
            "Epoch 993/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5641 - accuracy: 0.7296 - val_loss: 1.7022 - val_accuracy: 0.8201\n",
            "Epoch 994/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5662 - accuracy: 0.7273 - val_loss: 1.6941 - val_accuracy: 0.8346\n",
            "Epoch 995/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5457 - accuracy: 0.7277 - val_loss: 1.6949 - val_accuracy: 0.8251\n",
            "Epoch 996/1000\n",
            "149/149 [==============================] - 5s 31ms/step - loss: 1.5487 - accuracy: 0.7315 - val_loss: 1.7068 - val_accuracy: 0.8283\n",
            "Epoch 997/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5444 - accuracy: 0.7292 - val_loss: 1.6928 - val_accuracy: 0.8277\n",
            "Epoch 998/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5404 - accuracy: 0.7378 - val_loss: 1.6961 - val_accuracy: 0.8270\n",
            "Epoch 999/1000\n",
            "149/149 [==============================] - 5s 34ms/step - loss: 1.5585 - accuracy: 0.7326 - val_loss: 1.6995 - val_accuracy: 0.8264\n",
            "Epoch 1000/1000\n",
            "149/149 [==============================] - 5s 32ms/step - loss: 1.5699 - accuracy: 0.7298 - val_loss: 1.6982 - val_accuracy: 0.8447\n",
            "<keras.engine.sequential.Sequential object at 0x7facf46cc850>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulation"
      ],
      "metadata": {
        "id": "WR9ig22oJ_Nl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "mQGtl4T2Obwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4e0fed-4130-4c5b-9bc9-b9f130babcfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 41s 41s/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "java dicoding 18 jan modules dicoding\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"java\"\n",
        "seed_text_sentence=seed_text\n",
        "next_words = 5\n",
        "  \n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list)\n",
        "    predicted = np.argmax(predicted,axis=1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text_sentence += \" \" + output_word\n",
        "    seed_text = output_word\n",
        "print(seed_text_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pVUC6P6BT_7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c569eee2-75bf-433f-9162-17010a534eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "dropdown error dicoding\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"dropdown error\"\n",
        "next_words = 1\n",
        "  \n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list)\n",
        "    predicted = np.argmax(predicted,axis=1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "fBLfm1ysUK-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72bac139-c8c5-4ac2-f4cc-a9fd21ec526a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "kuis bermasalah dicoding 18 jan 2021 24\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"kuis bermasalah\"\n",
        "next_words = 5\n",
        "  \n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list)\n",
        "    predicted = np.argmax(predicted,axis=1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This next word that's been predicted looked \"not fine\", here's the reasons:**\n",
        "\n",
        "\n",
        "\n",
        "1.   Our model's accuracy is not reach at least 80%.\n",
        "2.   Limited good dataset that used to trained.\n",
        "3.   This nlp model tricky enough, adding new data not always make model better, because that data may be not necessarily good enough.\n",
        "\n"
      ],
      "metadata": {
        "id": "yOxqSUIDRhc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Savel Model in h5 Format and Downloading json File"
      ],
      "metadata": {
        "id": "2i--n4J3J1Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "model.save('model.h5')\n",
        "with open('tokenizer.json', 'w') as f:\n",
        "  f.write(json.dumps(tokenizer.to_json()))"
      ],
      "metadata": {
        "id": "qO1QixWDBmfx"
      },
      "execution_count": 44,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "v4ISDkBwG4q1",
        "e_MqnJL6LuFV",
        "gj_Y22lCPsWc",
        "mvAP90MgQhb4",
        "3bbKDUthQsBw",
        "iMhZqHFSQ89_",
        "ifJeJcv3RF7E",
        "-UnfwiHCRLTH",
        "WR9ig22oJ_Nl",
        "2i--n4J3J1Jf"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}